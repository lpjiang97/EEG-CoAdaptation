{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Motor Imagery Decoder\n",
    "Use this clean notebook to create the decoder that will classify future motor imagery data. Please see `Exploration_Enobio_Motor_Screening.ipnyb` for the full exploration.\n",
    "\n",
    "Nile Wilson 2019.01.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy import signal\n",
    "from mne.filter import filter_data\n",
    "\n",
    "import scipy.signal as scisig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "import csv\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadEEGData(filename, EEGdevice):\n",
    "    \"\"\" This function converts a single .easy file (from NIC2) to an easy-to-use dataframe.\n",
    "    Uses both the .easy file and .info file (containing metadata)\n",
    "    \n",
    "    ---- Input ----\n",
    "    filename: string containing the .easy filepath\n",
    "    \n",
    "    ---- Output ----\n",
    "    df: dataframe containing all the EEG, accelerometer, and event marker data\n",
    "    fs: sampling rate for the EEG data (Hz)\n",
    "    fs_accel: sampling rate for the accelerometer data (Hz)\n",
    "    \n",
    "    \"\"\"\n",
    "    if EEGdevice == 7:\n",
    "        x = 1\n",
    "    elif EEGdevice == 8:\n",
    "        # Read in the .easy file\n",
    "        df = pd.read_csv(filename, delimiter='\\t', header=None)\n",
    "\n",
    "        # Get metadata from the .info file\n",
    "        fname = filename[:-5] + '.info'\n",
    "        with open(fname) as f:\n",
    "            content = f.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "\n",
    "        # Get the channel names\n",
    "        channel_info = [x for x in content if 'Channel ' in x]\n",
    "        channel_names = []\n",
    "        for ch in range(len(channel_info)):\n",
    "            channel_names.append(channel_info[ch].split(': ')[1])\n",
    "\n",
    "        channel_names.append('X')\n",
    "        channel_names.append('Y')\n",
    "        channel_names.append('Z')\n",
    "        channel_names.append('STI 014')\n",
    "        channel_names.append('DateTime')\n",
    "\n",
    "        # Get sampling rates\n",
    "        sampling_rates = [x for x in content if 'sampling rate: ' in x]\n",
    "        fs_all = []\n",
    "        for freq in range(len(sampling_rates)):\n",
    "            tmp = sampling_rates[freq].split(': ')[1].split(' ')[0]\n",
    "            if tmp in ['N/A']:\n",
    "                print('Skipping N/A')\n",
    "            else:\n",
    "                fs_all.append(float(sampling_rates[freq].split(': ')[1].split(' ')[0]))\n",
    "\n",
    "        # Store sampling rates\n",
    "        fs = fs_all[0]\n",
    "        fs_accel = fs_all[1]\n",
    "\n",
    "        # Assign the column names\n",
    "        df.columns = channel_names\n",
    "    \n",
    "    # Return dataframe and sampling rates\n",
    "    return df, fs, fs_accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadBehavioralData(filename_behavioral):\n",
    "    \"\"\"\n",
    "    This function loads behavioral data for the motor screening task and formats it to use in this script\n",
    "    \"\"\"\n",
    "    behavioralData = pd.read_csv(filename_behavioral, ',')\n",
    "    behavioralData = behavioralData.transpose()\n",
    "    behavioralHeader = behavioralData.iloc[0]\n",
    "    behavioralData = behavioralData.iloc[2:]\n",
    "    behavioralData.columns = behavioralHeader\n",
    "    \n",
    "    return behavioralData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SyncTriggerPulses(EEGdata, EEGdevice, fs, behavioralData):\n",
    "    \"\"\"\n",
    "    This function returns the indices for events of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    if EEGdevice == 7:\n",
    "        print('Put code here')\n",
    "    elif EEGdevice == 8:\n",
    "        # Store where the values in trigger are equal to 8 (the audio trigger input channel number)\n",
    "        index_trigger = np.where(EEGdata['STI 014']!=0)\n",
    "        index_trigger = index_trigger[0]\n",
    "        \n",
    "        # Check number of trials\n",
    "        num_of_trials = behavioralData.shape[0]\n",
    "        if num_of_trials > len(index_trigger):\n",
    "            num_of_trials = num_of_trials - 1\n",
    "            num_trials_removed = 1\n",
    "        else:\n",
    "            num_trials_removed = 0\n",
    "        \n",
    "        trialLength = int(behavioralData['trialLength'][0])\n",
    "\n",
    "        # Get trial timing\n",
    "        t_trial_start = list()\n",
    "        t_trial_end = list()\n",
    "\n",
    "        # Creating lists of all trigger start and end locations\n",
    "        for i in range(0,num_of_trials):\n",
    "            t_trial_start.append(index_trigger[i])\n",
    "            t_trial_end.append(index_trigger[i] + int(trialLength*fs))\n",
    "\n",
    "        # Save rest period epochs as well as trials for comparison\n",
    "        t_rest_start = list()\n",
    "        t_rest_end = list()\n",
    "\n",
    "        for i in range(num_of_trials-1):\n",
    "            t_rest_start.append(t_trial_end[i])\n",
    "            t_rest_end.append(t_trial_start[i+1])\n",
    "    \n",
    "    return num_of_trials, t_trial_start, t_trial_end, t_rest_start, t_rest_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EpochData(EEGdata, t_trial_start, t_trial_end):\n",
    "    \"\"\"\n",
    "    This function epochs the data\n",
    "    \"\"\"\n",
    "    \n",
    "    if EEGdevice == 7:\n",
    "        channels = EEGdata.columns[1:8]\n",
    "    elif EEGdevice == 8:\n",
    "        channels = EEGdata.columns[0:8]\n",
    "    \n",
    "    epochs = []\n",
    "    epochs_norm = []\n",
    "\n",
    "    for trial in range(0,len(t_trial_start)):\n",
    "        t_start = t_trial_start[trial]\n",
    "        t_end = t_trial_end[trial]\n",
    "\n",
    "        # Baseline\n",
    "        if trial == 0:\n",
    "            tb_start = t_trial_start[trial] - np.round(1.5*fs)\n",
    "            tb_end = t_trial_start[trial]\n",
    "        else:\n",
    "            tb_start = t_trial_end[trial-1]\n",
    "            tb_end = t_trial_start[trial]\n",
    "            \n",
    "        baseline = EEGdata.loc[tb_start:tb_end][channels]\n",
    "        \n",
    "        # Store epoch\n",
    "        tmp = (EEGdata.loc[t_start:t_end][channels] - np.mean(baseline))/np.std(baseline)\n",
    "        epochs_norm.append(tmp)\n",
    "        epochs.append(EEGdata.loc[t_start:t_end][channels])\n",
    "    \n",
    "    return epochs, epochs_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CutEpochs(epochs, fs, trial_type):\n",
    "    epochs_cut = []\n",
    "    trial_type_cut = list()\n",
    "\n",
    "    num_of_epochs = len(epochs)\n",
    "    full_epoch_length = np.shape(epochs[0])[0]\n",
    "    cut_epoch_length = int(1.750*fs)\n",
    "\n",
    "    sliding_window_starts = np.floor(np.linspace(1*fs, full_epoch_length - cut_epoch_length, 10))\n",
    "\n",
    "    # For each epoch\n",
    "    for epochOfInt in range(0,num_of_epochs):\n",
    "        # Reset the index within each epoch temporarily\n",
    "        reset_index = epochs[epochOfInt].reset_index(drop=True)\n",
    "\n",
    "        # Sliding window of 750 ms\n",
    "        for new_start in sliding_window_starts:\n",
    "            tmp = reset_index.loc[new_start:new_start+cut_epoch_length]\n",
    "            epochs_cut.append(tmp)\n",
    "            trial_type_cut.append(trial_type[epochOfInt])\n",
    "    \n",
    "    num_of_trials_cut = len(trial_type_cut)\n",
    "    \n",
    "    return epochs_cut, trial_type_cut, num_of_trials_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OrganizeTrials(behavioralData):\n",
    "    \"\"\"\n",
    "    Organizes trials\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create lists for each trial type\n",
    "    trialL = list()\n",
    "    trialR = list()\n",
    "    i = 0\n",
    "\n",
    "    for letter in behavioralData['trialType']:\n",
    "        if letter == 'L':\n",
    "            trialL.append(i)\n",
    "        elif letter == 'R':\n",
    "            trialR.append(i)\n",
    "        i += 1\n",
    "    \n",
    "    # Create a single list that includes which trial is which (L = 0, R = 1)\n",
    "    trial_type = list()\n",
    "    i = 0\n",
    "\n",
    "    for letter in behavioralData['trialType']:\n",
    "        if letter == 'L':\n",
    "            trial_type.append(0)\n",
    "        elif letter == 'R':\n",
    "            trial_type.append(1)\n",
    "        i += 1\n",
    "\n",
    "    return trial_type, trialL, trialR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeatures(epochs, num_of_trials, channelsToUse, ds_factor):\n",
    "    \"\"\"\n",
    "    Extract signal features of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the summed delta power for each trial\n",
    "    alpha_power = dict.fromkeys(channelsToUse)\n",
    "    beta_power = dict.fromkeys(channelsToUse)\n",
    "    ds_f = ds_factor # downsampling factor\n",
    "\n",
    "    for chanOfInt in channelsToUse:\n",
    "        tmp_alpha = list()\n",
    "        tmp_beta = list()\n",
    "\n",
    "        for trial in range(0, num_of_trials):\n",
    "            f, Pxx_den = signal.welch(signal.decimate(epochs[trial][chanOfInt],ds_f), fs/ds_f, scaling='spectrum')\n",
    "            alpha_idx = np.where(np.logical_and(np.round(f) > 8, np.round(f) <= 12))\n",
    "            tmp_alpha.append(np.sum(Pxx_den[alpha_idx]))\n",
    "\n",
    "            beta_idx = np.where(np.logical_and(np.round(f) > 13, np.round(f) <= 30))\n",
    "            tmp_beta.append(np.sum(Pxx_den[beta_idx]))\n",
    "\n",
    "        alpha_power[chanOfInt] = tmp_alpha\n",
    "        beta_power[chanOfInt] = tmp_beta\n",
    "    \n",
    "    return alpha_power, beta_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainDecoder(X, y):\n",
    "    \"\"\"\n",
    "    Trains the decoder on ALL the data (does not split into test and train because this is all train)\n",
    "    \"\"\"\n",
    "    # preprocess dataset, split into training and test part\n",
    "    args = np.arange(len(X))\n",
    "    np.random.shuffle(args)\n",
    "    X = [X[i] for i in args]\n",
    "    y = [y[i] for i in args]\n",
    "    X_not_scaled = X\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "\n",
    "    # Determine model parameters\n",
    "    activations = ['relu','tanh']\n",
    "    alphas = np.logspace(-6, 3, 10)\n",
    "    solvers = ['lbfgs','sgd']\n",
    "    hyper_params = {\"activation\":activations, \"alpha\":alphas, \"solver\":solvers}\n",
    "    grid = GridSearchCV(MLPClassifier(learning_rate='constant', random_state=1), param_grid=hyper_params, cv=KFold(n_splits=5), verbose=True)\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    # Fit the model\n",
    "    clf = grid.best_estimator_\n",
    "    clf.fit(X,y)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Split into train and test for evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Fit the model\n",
    "    clf = grid.best_estimator_\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    print(grid.best_estimator_)\n",
    "    print('-----------')\n",
    "    print('score: ' + str(score))\n",
    "    print(confusion_matrix(y_test, clf.predict(X_test)))\n",
    "    print('-----------')\n",
    "    \"\"\"\n",
    "    \n",
    "    return clf, X, X_not_scaled, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveDecoderAndData(clf, X, X_not_scaled, y, subjID):\n",
    "    \"\"\"\n",
    "    Save the decoder and the data it was trained/tested on\n",
    "    \"\"\"\n",
    "    time_to_save = datetime.datetime.now().isoformat()\n",
    "    time_to_save = time_to_save.replace('T','-')\n",
    "    time_to_save = time_to_save.replace(':','-')\n",
    "    \n",
    "    model = clf\n",
    "    model_file = 'Models/' + subjID + '_MI_classifier_' + time_to_save[:19] + '.sav'\n",
    "    pickle.dump(model, open(model_file, 'wb'))\n",
    "    \n",
    "    filepath_export_data = 'Models/' + subjID + '_data_for_MI_classifier_' + time_to_save[:19] + '.npz'\n",
    "    np.savez_compressed(filepath_export_data, X=X, X_not_scaled=X_not_scaled, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables to Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjID = 'nile'\n",
    "EEGdevice = 8 # 7 for DSI-7, 8 for Enobio\n",
    "filename_eeg = 'SaveData/20190130121649_nile_Motor_Screening.easy'\n",
    "filename_behavioral = 'SaveData/nile_Motor_Screening_R1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping N/A\n",
      "Creating RawArray with float64 data, n_channels=7, n_times=299066\n",
      "    Range : 0 ... 299065 =      0.000 ...   598.130 secs\n",
      "Ready.\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "l_trans_bandwidth chosen to be 1.0 Hz\n",
      "h_trans_bandwidth chosen to be 10.0 Hz\n",
      "Filter length of 1651 samples (3.302 sec) selected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    }
   ],
   "source": [
    "# Load EEG data\n",
    "EEGdata, fs, fs_accel = LoadEEGData(filename_eeg, EEGdevice)\n",
    "\n",
    "# Load behavioral data\n",
    "behavioralData = LoadBehavioralData(filename_behavioral)\n",
    "\n",
    "# Sync up trigger pulses\n",
    "num_of_trials, t_trial_start, t_trial_end, t_rest_start, t_rest_end = SyncTriggerPulses(EEGdata, EEGdevice, fs, behavioralData)\n",
    "\n",
    "# Clean the data\n",
    "EEGdata_orig = EEGdata.copy()\n",
    "lf = 1\n",
    "hf = 40\n",
    "\n",
    "if EEGdevice == 7:\n",
    "    channels = EEGdata.columns[1:8]\n",
    "elif EEGdevice == 8:\n",
    "    channels = EEGdata.columns[0:8]\n",
    "\n",
    "# Format our data into an mne-friendly format\n",
    "ch_types = ['eeg']*len(channels)\n",
    "info = mne.create_info(ch_names=list(channels), sfreq=fs, ch_types=ch_types)\n",
    "rawData = EEGdata[channels].values\n",
    "rawData = np.transpose(rawData)\n",
    "raw = mne.io.array.RawArray(rawData, info)\n",
    "raw.set_montage(mne.channels.read_montage(kind='standard_1020'))\n",
    "raw.filter(l_freq=lf, h_freq=hf)\n",
    "\n",
    "# Make a copy of the original data just in case\n",
    "EEGdata[channels] = raw.get_data().T\n",
    "\n",
    "# Epoch the data\n",
    "epochs, epochs_norm = EpochData(EEGdata, t_trial_start, t_trial_end)\n",
    "\n",
    "# Organize trial types\n",
    "trial_type, trialL, trialR = OrganizeTrials(behavioralData)\n",
    "\n",
    "# Cut epochs into 750 ms chunks\n",
    "epochs_cut, trial_type_cut, num_of_trials_cut = CutEpochs(epochs_norm, fs, trial_type)\n",
    "\n",
    "# Get signal features\n",
    "alpha_power, beta_power = ExtractFeatures(epochs_cut, num_of_trials_cut, ['C3','C4'], 1)\n",
    "motor_features = [alpha_power['C3'], alpha_power['C4'], beta_power['C3'], beta_power['C4']]\n",
    "motor_features = np.transpose(motor_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each color is a different feature (alpha and beta power for C3 and C4)\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(motor_features, bins='auto')\n",
    "plt.xlabel('Motor Feature Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of motor_features')\n",
    "plt.show()\n",
    "print('Each color is a different feature (alpha and beta power for C3 and C4)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1172061 , 0.26986735, 0.29361296, 0.54411065],\n",
       "       [0.10873798, 0.27677116, 0.30807692, 0.54805438],\n",
       "       [0.1082541 , 0.25327512, 0.26539241, 0.44795396],\n",
       "       ...,\n",
       "       [0.03504125, 0.08010745, 0.12194143, 0.12499475],\n",
       "       [0.03020208, 0.05099684, 0.11873638, 0.12420641],\n",
       "       [0.03987682, 0.05767268, 0.1241643 , 0.13818258]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motor_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47007737,  2.01526324,  0.5503876 ,  3.60414573],\n",
       "       [ 0.31851625,  2.10394163,  0.68890108,  3.6470041 ],\n",
       "       [ 0.30985581,  1.80213863,  0.2801347 ,  2.55916395],\n",
       "       ...,\n",
       "       [-1.0004979 , -0.42217346, -1.09361754, -0.95059158],\n",
       "       [-1.08710856, -0.79609472, -1.12431054, -0.95915885],\n",
       "       [-0.91395145, -0.7103446 , -1.07233025, -0.80727294]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StandardScaler().fit_transform(motor_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mess around with decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = np.arange(len(motor_features))\n",
    "np.random.shuffle(args)\n",
    "X = [motor_features[i] for i in args]\n",
    "y = [trial_type_cut[i] for i in args]\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter tuning for SVM\n",
    "Cs = [0.001, 0.01, 0.1, 1, 1.5, 2, 5]\n",
    "degrees = [1, 2, 3, 4, 5]\n",
    "hyper_params = {\"C\":Cs, \"degree\":degrees}\n",
    "grid = GridSearchCV(SVC(kernel='rbf', gamma='auto'), param_grid=hyper_params, cv=KFold(n_splits=50), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 35 candidates, totalling 1750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1750 out of 1750 | elapsed:   26.2s finished\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=1, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Fit\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_estimator_\n",
    "\n",
    "# Score\n",
    "svc = grid.best_estimator_\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.7388167388167388\n",
      "test score: 0.696969696969697\n",
      "[[ 93  62]\n",
      " [ 28 114]]\n"
     ]
    }
   ],
   "source": [
    "print('train score: ' + str(svc.score(X_train, y_train)))\n",
    "print('test score: ' + str(svc.score(X_test, y_test)))\n",
    "print(confusion_matrix(y_test, svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter tuning for SVM\n",
    "Cs = [0.001, 0.01, 0.1, 1, 1.5, 2, 5]\n",
    "degrees = [1, 2, 3, 4, 5]\n",
    "hyper_params = {\"C\":Cs, \"degree\":degrees}\n",
    "grid = GridSearchCV(SVC(kernel='linear', gamma='auto'), param_grid=hyper_params, cv=KFold(n_splits=50), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 35 candidates, totalling 1750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1750 out of 1750 | elapsed:   17.1s finished\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=1, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Fit\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_estimator_\n",
    "\n",
    "# Score\n",
    "svc = grid.best_estimator_\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.6046176046176046\n",
      "test score: 0.5791245791245792\n",
      "[[ 70  96]\n",
      " [ 29 102]]\n"
     ]
    }
   ],
   "source": [
    "print('train score: ' + str(svc.score(X_train, y_train)))\n",
    "print('test score: ' + str(svc.score(X_test, y_test)))\n",
    "print(confusion_matrix(y_test, svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay let's try the neural net again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:   43.8s finished\n"
     ]
    }
   ],
   "source": [
    "args = np.arange(len(motor_features))\n",
    "np.random.shuffle(args)\n",
    "X = [motor_features[i] for i in args]\n",
    "y = [trial_type_cut[i] for i in args]\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Determine model parameters\n",
    "activations = ['relu','tanh']\n",
    "alphas = np.logspace(-6, 3, 10)\n",
    "solvers = ['lbfgs','sgd']\n",
    "hyper_params = {\"activation\":activations, \"alpha\":alphas, \"solver\":solvers}\n",
    "grid = GridSearchCV(MLPClassifier(learning_rate='constant', random_state=1), param_grid=hyper_params, cv=KFold(n_splits=5), verbose=True)\n",
    "\n",
    "# Split into train and test for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Fit the model\n",
    "clf = grid.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "-----------\n",
      "score: 0.7474747474747475\n",
      "[[110  40]\n",
      " [ 35 112]]\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)\n",
    "print('-----------')\n",
    "print('score: ' + str(score))\n",
    "print(confusion_matrix(y_test, clf.predict(X_test)))\n",
    "print('-----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okay can now automate train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "clf, X, X_not_scaled, y = TrainDecoder(motor_features, trial_type_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save decoder and data it was trained/tested on\n",
    "SaveDecoderAndData(clf, X, X_not_scaled, y, subjID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
