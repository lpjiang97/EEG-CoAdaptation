{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create General Models\n",
    "Use this notebook to create the genreal models used to simulate transfer learning for subjects. In this notebook, we will load in the models and data used from the run with highest performance from all subjects **excluding** the subject we are simulating transfer learning for.\n",
    "\n",
    "Nile Wilson, 2019.03.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy import signal\n",
    "from mne.filter import filter_data\n",
    "from statistics import mode\n",
    "\n",
    "import scipy.signal as scisig\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random\n",
    "import pickle\n",
    "import glob\n",
    "import csv\n",
    "import mne\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjOfInt = 'a1e6c0'\n",
    "subject_group = 1\n",
    "EEGdevice = 8\n",
    "\n",
    "# model_type will be used to name/organize all files associated with whatever you run here\n",
    "# don't use the word 'original' here\n",
    "# Usually either 'experimental' or 'SVM01'\n",
    "model_type = 'experimental'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetBehavioralTL_Direct(behavioralData_all):\n",
    "    # When the target is to the left\n",
    "    trialL = np.where(behavioralData_all['target_x'] < 1000)\n",
    "    movementL = np.where(behavioralData_all['direction_moved'] == 'left')\n",
    "\n",
    "    # When target was to the right\n",
    "    trialR = np.where(behavioralData_all['target_x'] > 1000)\n",
    "    movementR = np.where(behavioralData_all['direction_moved'] == 'right')\n",
    "\n",
    "    # Create a single list that includes which movement is which (L = 0, R = 1)\n",
    "    trial_type = np.zeros([1,len(behavioralData_all['score'])])\n",
    "    trial_type[0][trialL] = 0\n",
    "    trial_type[0][trialR] = 1\n",
    "    trial_type = np.round(trial_type[0])\n",
    "\n",
    "    direction_moved = np.zeros([1,len(behavioralData_all['score'])])\n",
    "    direction_moved[0][movementL] = 0\n",
    "    direction_moved[0][movementR] = 1\n",
    "    direction_moved = np.round(direction_moved[0])\n",
    "    \n",
    "    actual = direction_moved\n",
    "    TL = trial_type\n",
    "    return actual, TL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for simulating performance just to get scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadModel_MI(subjID, run_number=0, session_number=1, adaptationType='CS'):\n",
    "    \"\"\"\n",
    "    This function loads the most recent motor imagery classifier\n",
    "    for this subject by default. Current run minus 1.\n",
    "    \n",
    "    You may also select which number model (from original to most recent)\n",
    "    by using a value from 0 (original) to 4 (most recent)\n",
    "    \"\"\"\n",
    "    runOfInt= run_number\n",
    "    run_number = runOfInt - 1\n",
    "    # Load latest model and its associated data\n",
    "    \n",
    "    if adaptationType == 'CS' or adaptationType == 'None':\n",
    "        models = glob.glob('Models/' + subjID + '/Session' + str(session_number) + '/' + subjID + '_MI_classifier_*')\n",
    "        models_data_list = glob.glob('Models/' + subjID + '/Session' + str(session_number) + '/' + subjID + '_data_for_MI_classifier_*')\n",
    "    elif adaptationType == 'TL':\n",
    "        models = glob.glob('Models/' + subjID + '/Session' + str(session_number) + '/' + subjID + '_MI_classifier_TL_*')\n",
    "        models_data_list = glob.glob('Models/' + subjID + '/Session' + str(session_number) + '/' + subjID + '_data_for_MI_classifier_TL_*')\n",
    "    \n",
    "    # Throw exception if model number is outside range of existing models\n",
    "    if run_number > len(models):\n",
    "        raise ValueError('Please select a valid model number')\n",
    "    if adaptationType == 'TL':\n",
    "        run_number = -1\n",
    "    print('run_number: ' + str(run_number))\n",
    "    model_file = models[run_number] # load the most recent model\n",
    "    print('Selecting model: ' + model_file)\n",
    "    clf = pickle.load(open(model_file, 'rb'))\n",
    "\n",
    "    models_data = models_data_list[run_number] # load the most recent model\n",
    "    MI_data = np.load(models_data)\n",
    "    X_loaded = MI_data['X_not_scaled']\n",
    "    X_loaded_scaled = MI_data['X']\n",
    "    y_loaded = MI_data['y']\n",
    "    \n",
    "    return clf, X_loaded, X_loaded_scaled, y_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadModel_Error(subjID):\n",
    "    # Load the error detection model and see what featureType it used (frequency or template projections)\n",
    "    models = glob.glob('Models/' + subjID + '/Session1/' + subjID + '_Error_classifier_*') #always load session1 error\n",
    "    model_file = models[-1] # load the most recent model\n",
    "    clf_error = pickle.load(open(model_file, 'rb'))\n",
    "    print(model_file)\n",
    "    print(clf_error)\n",
    "\n",
    "    models_data_list = glob.glob('Models/' + subjID + '/Session1/' + subjID + '_data_for_Error_classifier_*')\n",
    "    models_data = models_data_list[-1] # load the most recent model\n",
    "    loaded_data = np.load(models_data)\n",
    "    featureType = loaded_data['featureType']\n",
    "\n",
    "    # Load templates if applicable\n",
    "    error_template = loaded_data['error_template'].tolist()\n",
    "    correct_template = loaded_data['correct_template'].tolist()\n",
    "    \n",
    "    # The data\n",
    "    X_loaded = loaded_data['X']\n",
    "    y_loaded = loaded_data['y']\n",
    "    \n",
    "    return clf_error, featureType, X_loaded, y_loaded, error_template, correct_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Subject Demographics\n",
    "First get the subject demographics loaded. Note that 'useBehavioral' indicates whether the subject had their data collective with the bug in the experimental code (useBehavioral = 'No') or if they were collected recently after the fix (useBehavioral = 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Group Number</th>\n",
       "      <th>Moving MI</th>\n",
       "      <th>Session 1</th>\n",
       "      <th>Session 2</th>\n",
       "      <th>Session 3</th>\n",
       "      <th>Handedness</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>History of Neurological Disorders</th>\n",
       "      <th>Cap Size</th>\n",
       "      <th>useBehavioral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b12a46</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>No</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41d8ff</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>21</td>\n",
       "      <td>No</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1e8b34</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>No</td>\n",
       "      <td>L</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ad11cf</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>Yes</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b7ff16</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>No</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject ID  Group Number Moving MI  Session 1  Session 2  Session 3  \\\n",
       "0     b12a46             1        No          0          8         15   \n",
       "1     41d8ff             1        No          0          5         12   \n",
       "2     1e8b34             1        No          0          3         14   \n",
       "3     ad11cf             1        No          0          7         12   \n",
       "4     b7ff16             2        No          0         19         21   \n",
       "\n",
       "  Handedness Sex  Age History of Neurological Disorders Cap Size useBehavioral  \n",
       "0          R   M   21                                No        M            No  \n",
       "1          R   F   21                                No        M            No  \n",
       "2          R   M   29                                No        L            No  \n",
       "3          R   F   20                               Yes        M            No  \n",
       "4          R   F   20                                No        M            No  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_all = pd.read_csv('subject_demographics.csv')\n",
    "generalSubjects = list(demographics_all['Subject ID'])\n",
    "demographics_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Group Number</th>\n",
       "      <th>Moving MI</th>\n",
       "      <th>Session 1</th>\n",
       "      <th>Session 2</th>\n",
       "      <th>Session 3</th>\n",
       "      <th>Handedness</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>History of Neurological Disorders</th>\n",
       "      <th>Cap Size</th>\n",
       "      <th>useBehavioral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b12a46</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>No</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41d8ff</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>21</td>\n",
       "      <td>No</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1e8b34</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>R</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>No</td>\n",
       "      <td>L</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ad11cf</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>Yes</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b7ff16</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>No</td>\n",
       "      <td>M</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject ID  Group Number Moving MI  Session 1  Session 2  Session 3  \\\n",
       "0     b12a46             1        No          0          8         15   \n",
       "1     41d8ff             1        No          0          5         12   \n",
       "2     1e8b34             1        No          0          3         14   \n",
       "3     ad11cf             1        No          0          7         12   \n",
       "4     b7ff16             2        No          0         19         21   \n",
       "\n",
       "  Handedness Sex  Age History of Neurological Disorders Cap Size useBehavioral  \n",
       "0          R   M   21                                No        M            No  \n",
       "1          R   F   21                                No        M            No  \n",
       "2          R   M   29                                No        L            No  \n",
       "3          R   F   20                               Yes        M            No  \n",
       "4          R   F   20                                No        M            No  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the subject of interest\n",
    "demo = demographics_all.copy()\n",
    "demo.drop(demo.loc[demo['Subject ID'] == subjOfInt].index[0])\n",
    "demo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generalSubjects = list(demo['Subject ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the Classifiers\n",
    "Load in the Motor Imagery classifiers, and their data, which were used during the highest performance run for each subject. Also load in the respective error classifier for each subjects. Note: there was only one error classifier per subject so we do not need to try and find this by run of best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting performance data file: 2019-03-29-17-25-46_all_scores_for_2-way_ANOVA_sessions.sav.mat\n"
     ]
    }
   ],
   "source": [
    "# Load most recent performance data file\n",
    "# There should only be one in the end (but making many for testing now)\n",
    "data_files = glob.glob('2019*_all_scores_for_2-way_ANOVA_sessions.sav.mat')\n",
    "filename = data_files[-1]\n",
    "print('Selecting performance data file: ' + filename)\n",
    "\n",
    "# Load the contents\n",
    "mat_contents = sio.loadmat(filename)\n",
    "\n",
    "scores = mat_contents['all_scores_export'][0]\n",
    "adaptation_scheme = mat_contents['AdaptationScheme']\n",
    "session_number = list()\n",
    "run_number = list()\n",
    "subject = mat_contents['Subject']\n",
    "\n",
    "# handedness = mat_contents['Handedness']\n",
    "# age = mat_contents['Age'][0]\n",
    "\n",
    "# Remove excess white space and convert session and run num to numbers\n",
    "for i in range(0,len(adaptation_scheme)):\n",
    "    adaptation_scheme[i] = adaptation_scheme[i].strip()\n",
    "    session_number.append(int(re.sub(\"[^0-9]\", \"\", mat_contents['SessionNumber'][i])))\n",
    "    run_number.append(int(re.sub(\"[^0-9]\", \"\", mat_contents['RunNumber'][i])))\n",
    "    \n",
    "session_number = np.asarray(session_number)\n",
    "run_number = np.asarray(run_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the run and session number containing the max score for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMOVE THE [0:10]\n",
    "The range is just there to prevent running on subjects where we don't have the data yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab empty\n",
      "run_number: 1\n",
      "Selecting model: Models/b12a46/Session2\\b12a46_MI_classifier_2019-02-21-12-32-38.sav\n",
      "Models/b12a46/Session1\\b12a46_Error_classifier_2019-02-06-10-23-55.sav\n",
      "MLPClassifier(activation='relu', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "ab empty\n",
      "run_number: 0\n",
      "Selecting model: Models/41d8ff/Session2\\41d8ff_MI_classifier_2019-02-13-16-26-08.sav\n",
      "Models/41d8ff/Session1\\41d8ff_Error_classifier_2019-02-08-11-36-57.sav\n",
      "MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "ab empty\n",
      "run_number: 2\n",
      "Selecting model: Models/1e8b34/Session2\\1e8b34_MI_classifier_2019-02-22-09-37-52.sav\n",
      "Models/1e8b34/Session1\\1e8b34_Error_classifier_2019-02-19-10-42-51.sav\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "ab empty\n",
      "run_number: 1\n",
      "Selecting model: Models/ad11cf/Session3\\ad11cf_MI_classifier_2019-02-27-09-45-51.sav\n",
      "Models/ad11cf/Session1\\ad11cf_Error_classifier_2019-02-15-16-21-26.sav\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "ac empty\n",
      "run_number: 1\n",
      "Selecting model: Models/b7ff16/Session3\\b7ff16_MI_classifier_2019-02-28-09-20-41.sav\n",
      "Models/b7ff16/Session1\\b7ff16_Error_classifier_2019-02-07-16-24-04.sav\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "ac empty\n",
      "run_number: 1\n",
      "Selecting model: Models/42feb7/Session3\\42feb7_MI_classifier_2019-03-12-13-28-47.sav\n",
      "Models/42feb7/Session1\\42feb7_Error_classifier_2019-03-05-13-20-11.sav\n",
      "MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "ac empty\n",
      "run_number: 0\n",
      "Selecting model: Models/9d4921/Session1\\9d4921_MI_classifier_2019-02-19-15-03-30.sav\n",
      "Models/9d4921/Session1\\9d4921_Error_classifier_2019-02-19-14-51-45.sav\n",
      "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "ac empty\n",
      "run_number: 4\n",
      "Selecting model: Models/05ecbc/Session2\\05ecbc_MI_classifier_2019-02-14-15-06-17.sav\n",
      "Models/05ecbc/Session1\\05ecbc_Error_classifier_2019-02-07-12-50-42.sav\n",
      "MLPClassifier(activation='tanh', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "ab empty\n",
      "run_number: 4\n",
      "Selecting model: Models/af9af3/Session1\\af9af3_MI_classifier_2019-02-22-14-05-31.sav\n",
      "Models/af9af3/Session1\\af9af3_Error_classifier_2019-02-22-13-24-13.sav\n",
      "MLPClassifier(activation='relu', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "ab empty\n",
      "run_number: 1\n",
      "Selecting model: Models/c795d2/Session1\\c795d2_MI_classifier_2019-02-21-12-25-15.sav\n",
      "Models/c795d2/Session1\\c795d2_Error_classifier_2019-02-13-11-55-09.sav\n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "max_scores = list()\n",
    "max_runs = list()\n",
    "max_sessions = list()\n",
    "all_clf = list()\n",
    "all_X_loaded = list()\n",
    "all_X_loaded_scaled = list()\n",
    "all_y_loaded = list()\n",
    "error_clf = list()\n",
    "error_X_loaded = list()\n",
    "error_y_loaded = list()\n",
    "error_featureType = list()\n",
    "error_error_template = list()\n",
    "error_correct_template = list()\n",
    "\n",
    "for subjOfInt in generalSubjects[0:10]:\n",
    "\n",
    "    # Find original scores ('co-adaptation' or 'no adaptation')\n",
    "    a = np.where(subject==subjOfInt)[0]\n",
    "    b = np.where(adaptation_scheme=='co-adaptation')[0]\n",
    "    c = np.where(adaptation_scheme=='no adaptation')[0]\n",
    "    ab = list(set(a) & set(b)) # finding common row numbers\n",
    "    ac = list(set(a) & set(c))\n",
    "\n",
    "    if not ab:\n",
    "        print('ab empty')\n",
    "        toUse = ac\n",
    "        adaptationType = 'None'\n",
    "    if not ac:\n",
    "        print('ac empty')\n",
    "        toUse = ab\n",
    "        adaptationType = 'CS'\n",
    "    toUse.sort()\n",
    "    \n",
    "    max_score = np.max(scores[toUse])\n",
    "    max_idx = np.argmax(scores[toUse])\n",
    "    max_run = run_number[toUse][max_idx]\n",
    "    max_session = session_number[toUse][max_idx]\n",
    "    \n",
    "    # Add to list\n",
    "    max_scores.append(max_score)\n",
    "    max_runs.append(max_run)\n",
    "    max_sessions.append(max_session)\n",
    "    \n",
    "    # Load the MI model that led to max score\n",
    "    clf, X_loaded, X_loaded_scaled, y_loaded = LoadModel_MI(subjOfInt, run_number=max_run,\n",
    "                                                            session_number=max_session,\n",
    "                                                            adaptationType=adaptationType)\n",
    "    all_clf.append(clf)\n",
    "    all_X_loaded.append(X_loaded)\n",
    "    all_X_loaded_scaled.append(X_loaded_scaled)\n",
    "    all_y_loaded.append(y_loaded)\n",
    "    \n",
    "    # Load in the error model\n",
    "    clf_error, featureType, X_loaded, y_loaded, error_template, correct_template = LoadModel_Error(subjOfInt)\n",
    "    error_clf.append(clf_error)\n",
    "    error_featureType.append(featureType)\n",
    "    error_X_loaded.append(X_loaded)\n",
    "    error_y_loaded.append(y_loaded)\n",
    "    error_error_template.append(error_template)\n",
    "    error_correct_template.append(correct_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create general models\n",
    "Use the loaded data to create a general MI classifier and a general error classifier which will be tested on the subject of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mode, so chosing at random\n"
     ]
    }
   ],
   "source": [
    "# Find the most common of all parameters\n",
    "all_activation = list()\n",
    "all_alpha = list()\n",
    "all_batch_size = list()\n",
    "all_beta_1 = list()\n",
    "all_beta_2 = list()\n",
    "all_early_stopping = list()\n",
    "all_epsilon = list()\n",
    "all_hidden_layer_sizes = list()\n",
    "all_learning_rate = list()\n",
    "all_learning_rate_init = list()\n",
    "all_max_iter = list()\n",
    "all_momentum = list()\n",
    "all_n_iter_no_change = list()\n",
    "all_nesterovs_momentum = list()\n",
    "all_power_t = list()\n",
    "all_random_state = list()\n",
    "all_shuffle = list()\n",
    "all_solver = list()\n",
    "all_tol = list()\n",
    "all_validation_fraction = list()\n",
    "all_verbose = list()\n",
    "all_warm_start = list()\n",
    "\n",
    "for i in range(0,len(all_clf)):\n",
    "    all_activation.append(all_clf[i].activation)\n",
    "    all_alpha.append(all_clf[i].alpha)\n",
    "    all_batch_size.append(all_clf[i].batch_size)\n",
    "    all_beta_1.append(all_clf[i].beta_1)\n",
    "    all_beta_2.append(all_clf[i].beta_2)\n",
    "    all_early_stopping.append(all_clf[i].early_stopping)\n",
    "    all_epsilon.append(all_clf[i].epsilon)\n",
    "    all_hidden_layer_sizes.append(all_clf[i].hidden_layer_sizes)\n",
    "    all_learning_rate.append(all_clf[i].learning_rate)\n",
    "    all_learning_rate_init.append(all_clf[i].learning_rate_init)\n",
    "    all_max_iter.append(all_clf[i].max_iter)\n",
    "    all_momentum.append(all_clf[i].momentum)\n",
    "    all_n_iter_no_change.append(all_clf[i].n_iter_no_change)\n",
    "    all_nesterovs_momentum.append(all_clf[i].nesterovs_momentum)\n",
    "    all_power_t.append(all_clf[i].power_t)\n",
    "    all_random_state.append(all_clf[i].random_state)\n",
    "    all_shuffle.append(all_clf[i].shuffle)\n",
    "    all_solver.append(all_clf[i].solver)\n",
    "    all_tol.append(all_clf[i].tol)\n",
    "    all_validation_fraction.append(all_clf[i].validation_fraction)\n",
    "    all_verbose.append(all_clf[i].verbose)\n",
    "    all_warm_start.append(all_clf[i].warm_start)\n",
    "\n",
    "# Create catch for mode\n",
    "def mode2(x):\n",
    "    try:\n",
    "        y = mode(x)\n",
    "    except:\n",
    "        print('No mode, so chosing at random')\n",
    "        y = random.choice(x)\n",
    "    return y\n",
    "\n",
    "# Save the most common ones\n",
    "activation = mode2(all_activation)\n",
    "alpha = mode2(all_alpha)\n",
    "batch_size = mode2(all_batch_size)\n",
    "beta_1 = mode2(all_beta_1)\n",
    "beta_2 = mode2(all_beta_2)\n",
    "early_stopping = mode2(all_early_stopping)\n",
    "epsilon = mode2(all_epsilon)\n",
    "hidden_layer_sizes = mode2(all_hidden_layer_sizes)\n",
    "learning_rate = mode2(all_learning_rate)\n",
    "learning_rate_init = mode2(all_learning_rate_init)\n",
    "max_iter = mode2(all_max_iter)\n",
    "momentum = mode2(all_momentum)\n",
    "n_iter_no_change = mode2(all_n_iter_no_change)\n",
    "nesterovs_momentum = mode2(all_nesterovs_momentum)\n",
    "power_t = mode2(all_power_t)\n",
    "random_state = mode2(all_random_state)\n",
    "shuffle = mode2(all_shuffle)\n",
    "solver = mode2(all_solver)\n",
    "tol = mode2(all_tol)\n",
    "validation_fraction = mode2(all_validation_fraction)\n",
    "verbose = mode2(all_verbose)\n",
    "warm_start = mode2(all_warm_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train general MI classifier using these paremeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create using parameters\n",
    "clf_MI = MLPClassifier(activation=activation, alpha=alpha, batch_size=batch_size, beta_1=beta_1,\n",
    "                   beta_2=beta_2, early_stopping=early_stopping, epsilon=epsilon,\n",
    "                   hidden_layer_sizes=hidden_layer_sizes, learning_rate=learning_rate,\n",
    "                   learning_rate_init=learning_rate_init, max_iter=max_iter, momentum=momentum,\n",
    "                   n_iter_no_change=n_iter_no_change, nesterovs_momentum=nesterovs_momentum, power_t=power_t,\n",
    "                   random_state=random_state, shuffle=shuffle, solver=solver, tol=tol,\n",
    "                   validation_fraction=validation_fraction, verbose=verbose, warm_start=warm_start)\n",
    "clf_MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10650, 4)\n",
      "(10650,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all data\n",
    "X_not_scaled_MI = np.vstack(all_X_loaded)\n",
    "X_MI = np.vstack(all_X_loaded_scaled)\n",
    "y_MI = np.concatenate(all_y_loaded)\n",
    "\n",
    "print(np.shape(X_MI))\n",
    "print(np.shape(y_MI))\n",
    "\n",
    "# preprocess dataset, split into training and test part\n",
    "args = np.arange(len(X_MI))\n",
    "np.random.shuffle(args)\n",
    "X_not_scaled_MI = [X_not_scaled_MI[i] for i in args]\n",
    "X_MI = [X_MI[i] for i in args]\n",
    "y_MI = [y_MI[i] for i in args]\n",
    "\n",
    "# Resample to account for imbalance\n",
    "method = SMOTE(kind='regular')\n",
    "X_MI, y_MI = method.fit_sample(X_MI, y_MI)\n",
    "\n",
    "# Train on all data\n",
    "clf_MI.fit(X_MI, y_MI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train general error classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First get the most common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mode, so chosing at random\n"
     ]
    }
   ],
   "source": [
    "# Find the most common of all parameters\n",
    "all_activation = list()\n",
    "all_alpha = list()\n",
    "all_batch_size = list()\n",
    "all_beta_1 = list()\n",
    "all_beta_2 = list()\n",
    "all_early_stopping = list()\n",
    "all_epsilon = list()\n",
    "all_hidden_layer_sizes = list()\n",
    "all_learning_rate = list()\n",
    "all_learning_rate_init = list()\n",
    "all_max_iter = list()\n",
    "all_momentum = list()\n",
    "all_n_iter_no_change = list()\n",
    "all_nesterovs_momentum = list()\n",
    "all_power_t = list()\n",
    "all_random_state = list()\n",
    "all_shuffle = list()\n",
    "all_solver = list()\n",
    "all_tol = list()\n",
    "all_validation_fraction = list()\n",
    "all_verbose = list()\n",
    "all_warm_start = list()\n",
    "\n",
    "for i in range(0,len(error_clf)):\n",
    "    all_activation.append(error_clf[i].activation)\n",
    "    all_alpha.append(error_clf[i].alpha)\n",
    "    all_batch_size.append(error_clf[i].batch_size)\n",
    "    all_beta_1.append(error_clf[i].beta_1)\n",
    "    all_beta_2.append(error_clf[i].beta_2)\n",
    "    all_early_stopping.append(error_clf[i].early_stopping)\n",
    "    all_epsilon.append(error_clf[i].epsilon)\n",
    "    all_hidden_layer_sizes.append(error_clf[i].hidden_layer_sizes)\n",
    "    all_learning_rate.append(error_clf[i].learning_rate)\n",
    "    all_learning_rate_init.append(error_clf[i].learning_rate_init)\n",
    "    all_max_iter.append(error_clf[i].max_iter)\n",
    "    all_momentum.append(error_clf[i].momentum)\n",
    "    all_n_iter_no_change.append(error_clf[i].n_iter_no_change)\n",
    "    all_nesterovs_momentum.append(error_clf[i].nesterovs_momentum)\n",
    "    all_power_t.append(error_clf[i].power_t)\n",
    "    all_random_state.append(error_clf[i].random_state)\n",
    "    all_shuffle.append(error_clf[i].shuffle)\n",
    "    all_solver.append(error_clf[i].solver)\n",
    "    all_tol.append(error_clf[i].tol)\n",
    "    all_validation_fraction.append(error_clf[i].validation_fraction)\n",
    "    all_verbose.append(error_clf[i].verbose)\n",
    "    all_warm_start.append(error_clf[i].warm_start)\n",
    "\n",
    "# Create catch for mode\n",
    "def mode2(x):\n",
    "    try:\n",
    "        y = mode(x)\n",
    "    except:\n",
    "        print('No mode, so chosing at random')\n",
    "        y = random.choice(x)\n",
    "    return y\n",
    "\n",
    "# Save the most common ones\n",
    "activation = mode2(all_activation)\n",
    "alpha = mode2(all_alpha)\n",
    "batch_size = mode2(all_batch_size)\n",
    "beta_1 = mode2(all_beta_1)\n",
    "beta_2 = mode2(all_beta_2)\n",
    "early_stopping = mode2(all_early_stopping)\n",
    "epsilon = mode2(all_epsilon)\n",
    "hidden_layer_sizes = mode2(all_hidden_layer_sizes)\n",
    "learning_rate = mode2(all_learning_rate)\n",
    "learning_rate_init = mode2(all_learning_rate_init)\n",
    "max_iter = mode2(all_max_iter)\n",
    "momentum = mode2(all_momentum)\n",
    "n_iter_no_change = mode2(all_n_iter_no_change)\n",
    "nesterovs_momentum = mode2(all_nesterovs_momentum)\n",
    "power_t = mode2(all_power_t)\n",
    "random_state = mode2(all_random_state)\n",
    "shuffle = mode2(all_shuffle)\n",
    "solver = mode2(all_solver)\n",
    "tol = mode2(all_tol)\n",
    "validation_fraction = mode2(all_validation_fraction)\n",
    "verbose = mode2(all_verbose)\n",
    "warm_start = mode2(all_warm_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all templates and decide which ones to use when testing with the individual subject (will need to restrict by cap size because that effects the montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureTypes = list()\n",
    "for i in range(0,len(error_clf)):\n",
    "    featureTypes.append(str(error_featureType[i]))\n",
    "featureType = mode(featureTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_templates = error_error_template\n",
    "correct_templates = error_correct_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create using parameters\n",
    "clf_error = MLPClassifier(activation=activation, alpha=alpha, batch_size=batch_size, beta_1=beta_1,\n",
    "                   beta_2=beta_2, early_stopping=early_stopping, epsilon=epsilon,\n",
    "                   hidden_layer_sizes=hidden_layer_sizes, learning_rate=learning_rate,\n",
    "                   learning_rate_init=learning_rate_init, max_iter=max_iter, momentum=momentum,\n",
    "                   n_iter_no_change=n_iter_no_change, nesterovs_momentum=nesterovs_momentum, power_t=power_t,\n",
    "                   random_state=random_state, shuffle=shuffle, solver=solver, tol=tol,\n",
    "                   validation_fraction=validation_fraction, verbose=verbose, warm_start=warm_start)\n",
    "clf_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12030, 16)\n",
      "(12030,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all data\n",
    "X_error = np.vstack(error_X_loaded)\n",
    "y_error = np.concatenate(error_y_loaded)\n",
    "\n",
    "print(np.shape(X_error))\n",
    "print(np.shape(y_error))\n",
    "\n",
    "# preprocess dataset, split into training and test part\n",
    "args = np.arange(len(X_error))\n",
    "np.random.shuffle(args)\n",
    "X_error = [X_error[i] for i in args]\n",
    "y_error = [y_error[i] for i in args]\n",
    "\n",
    "# Resample to account for imbalance\n",
    "method = SMOTE(kind='regular')\n",
    "X_error, y_error = method.fit_sample(X_error, y_error)\n",
    "\n",
    "# Train on all data\n",
    "clf_error.fit(X_error, y_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the MI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'Models/General_Model_MI_excluding_' + subjOfInt + '.sav'\n",
    "pickle.dump(clf_MI, open(model_file, 'wb'))\n",
    "\n",
    "filepath_export_data = 'Models/Data_for_General_MI_classifier_excluding_' + subjOfInt + '.npz'\n",
    "np.savez_compressed(filepath_export_data, X=X_MI, X_not_scaled=X_not_scaled_MI, y=y_MI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the error model (saving all error and correct templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'Models/General_Model_error_excluding_' + subjOfInt + '.sav'\n",
    "pickle.dump(clf_error, open(model_file, 'wb'))\n",
    "\n",
    "filepath_export_data = 'Models/Data_for_General_error_classifier_excluding_' + subjOfInt + '.npz'\n",
    "np.savez_compressed(filepath_export_data, X=X_error, y=y_error, featureType=featureType, error_templates=error_templates, correct_templates=correct_templates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on subject\n",
    "In another notebook, simulate how the subject would perform using the general models and compare to how they actually did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to how they actually did during data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
