{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapt Motor Imagery classifier (loop) with confidence scores\n",
    "Use this clean notebook to create the code to update the MI classifier using confidence scores created from Error-related Potentials (ErrPs) and Default Mode Network (DMN) activity / attention. This notebook differs from `Adapt_MI_Decoder_Loop` in that it automatically creates all the decoders without you having to move files around (hide all files ahead of run of interest).\n",
    "\n",
    "Please see `Check_BCI_ErrP_with_Attention.ipnyb` for a version of this code with plotting / checks / tinkering\n",
    "\n",
    "Nile Wilson 2019.02.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy import signal\n",
    "from mne.filter import filter_data\n",
    "\n",
    "import scipy.signal as scisig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "import glob\n",
    "import csv\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for working with the BCI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindBCIFiles(subjID, run_number):\n",
    "    \"\"\"\n",
    "    Returns the file names for the BCI run of choice\n",
    "    \"\"\"\n",
    "    # Load latest model and its associated data\n",
    "    BCI_files = glob.glob('SaveData/*' + subjID + '_BCI.easy')\n",
    "    \n",
    "    # Throw exception if model number is outside range of existing models\n",
    "    if run_number-1 > len(BCI_files):\n",
    "        raise ValueError('Please select a valid run number')\n",
    "    \n",
    "    filename_eeg = BCI_files[run_number-1]\n",
    "    print('Selecting BCI EEG file: ' + filename_eeg)\n",
    "\n",
    "    behavioral_files = glob.glob('SaveData/BCI_' + subjID + '*.csv')\n",
    "    filename_behavioral = behavioral_files[run_number-1]\n",
    "    print('Selecting BCI behavioral file: ' + filename_behavioral)\n",
    "    \n",
    "    return filename_eeg, filename_behavioral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadEEGData(filename, EEGdevice):\n",
    "    \"\"\" This function converts a single .easy file (from NIC2) to an easy-to-use dataframe.\n",
    "    Uses both the .easy file and .info file (containing metadata)\n",
    "    \n",
    "    ---- Input ----\n",
    "    filename: string containing the .easy filepath\n",
    "    \n",
    "    ---- Output ----\n",
    "    df: dataframe containing all the EEG, accelerometer, and event marker data\n",
    "    fs: sampling rate for the EEG data (Hz)\n",
    "    fs_accel: sampling rate for the accelerometer data (Hz)\n",
    "    \n",
    "    \"\"\"\n",
    "    if EEGdevice == 7:\n",
    "        x = 1\n",
    "    elif EEGdevice == 8:\n",
    "        # Read in the .easy file\n",
    "        df = pd.read_csv(filename, delimiter='\\t', header=None)\n",
    "\n",
    "        # Get metadata from the .info file\n",
    "        fname = filename[:-5] + '.info'\n",
    "        with open(fname) as f:\n",
    "            content = f.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "\n",
    "        # Get the channel names\n",
    "        channel_info = [x for x in content if 'Channel ' in x]\n",
    "        channel_names = []\n",
    "        for ch in range(len(channel_info)):\n",
    "            channel_names.append(channel_info[ch].split(': ')[1])\n",
    "\n",
    "        channel_names.append('X')\n",
    "        channel_names.append('Y')\n",
    "        channel_names.append('Z')\n",
    "        channel_names.append('STI 014')\n",
    "        channel_names.append('DateTime')\n",
    "\n",
    "        # Get sampling rates\n",
    "        sampling_rates = [x for x in content if 'sampling rate: ' in x]\n",
    "        fs_all = []\n",
    "        for freq in range(len(sampling_rates)):\n",
    "            tmp = sampling_rates[freq].split(': ')[1].split(' ')[0]\n",
    "            if tmp in ['N/A']:\n",
    "                print('Skipping N/A')\n",
    "            else:\n",
    "                fs_all.append(float(sampling_rates[freq].split(': ')[1].split(' ')[0]))\n",
    "\n",
    "        # Store sampling rates\n",
    "        fs = fs_all[0]\n",
    "        fs_accel = fs_all[1]\n",
    "\n",
    "        # Assign the column names\n",
    "        df.columns = channel_names\n",
    "    \n",
    "    # Return dataframe and sampling rates\n",
    "    return df, fs, fs_accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadBehavioralDataBCI(filename_behavioral):\n",
    "    \"\"\"\n",
    "    This function loads behavioral data for the motor screening task and formats it to use in this script\n",
    "    \"\"\"\n",
    "    behavioralData = pd.read_csv(filename_behavioral, ',')\n",
    "    \n",
    "    return behavioralData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SyncTriggerPulsesBCI(EEGdata, EEGdevice, fs, behavioralData):\n",
    "    \"\"\"\n",
    "    This function returns the indices for events of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    if EEGdevice == 7:\n",
    "        print('Put code here')\n",
    "    elif EEGdevice == 8:\n",
    "        # Store where the values in trigger are equal to 8 (the audio trigger input channel number)\n",
    "        index_trigger = np.where(EEGdata['STI 014']!=0)\n",
    "        index_trigger = index_trigger[0]\n",
    "\n",
    "        # Number of trials is greater than number of total pulses sent\n",
    "        # 999 when the task ends\n",
    "        move_left_starts = np.where(EEGdata['STI 014'] == 1)[0]\n",
    "        move_right_starts = np.where(EEGdata['STI 014'] == 2)[0]\n",
    "        rest_starts = np.where(EEGdata['STI 014'] == 3)[0]\n",
    "        rest_ends = np.where(EEGdata['STI 014'] == 4)[0]\n",
    "        \n",
    "        # If the number of rest_starts and rest_ends don't match, drop the extra one\n",
    "        # there should, by default, only be 12 starts and 12 ends\n",
    "\n",
    "        if len(rest_ends) > len(rest_starts):\n",
    "            if rest_ends[0] < rest_starts[0]:\n",
    "                rest_ends = rest_ends[1:]\n",
    "        elif len(rest_ends) < len(rest_starts):\n",
    "            if rest_ends[0] > rest_starts[0]:\n",
    "                rest_starts = rest_starts[1:]\n",
    "        \n",
    "        move_starts = np.sort(np.concatenate((move_left_starts,move_right_starts),0))\n",
    "        total_movements = len(move_starts)\n",
    "\n",
    "        # exclude movements that occur without defined baseline (if you need to get rid of first rest)\n",
    "        hasBaseline = list()\n",
    "        for movement in range(0,len(move_starts)):\n",
    "            hasBaseline.append(True in (rest_starts < move_starts[movement]))\n",
    "\n",
    "        np.where(hasBaseline)\n",
    "        move_starts = move_starts[np.where(hasBaseline)]\n",
    "\n",
    "        # exclude the move lefts and move rights that were thrown out in move_starts\n",
    "        for movement in range(0,total_movements):\n",
    "            if hasBaseline[movement] is False:\n",
    "                # for the left movements\n",
    "                idx_left = np.where(move_left_starts == move_starts[movement])\n",
    "                idx_left = np.asarray(idx_left)\n",
    "                idx_right = np.where(move_right_starts == move_starts[movement])\n",
    "                idx_right = np.asarray(idx_right)\n",
    "\n",
    "                if idx_left.size > 0:\n",
    "                    move_left_starts = np.delete(move_left_starts, idx_left)\n",
    "                if idx_right.size > 0:\n",
    "                    move_right_starts = np.delete(move_right_starts, idx_right)\n",
    "                \n",
    "        num_of_trials = len(rest_starts)\n",
    "        num_of_movements = len(move_left_starts) + len(move_right_starts)\n",
    "    \n",
    "    return num_of_trials, num_of_movements, move_starts, hasBaseline, rest_starts, rest_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EpochBCIData(EEGdata, move_starts, rest_starts, rest_ends):\n",
    "    \"\"\"\n",
    "    This function epochs the data\n",
    "    \"\"\"\n",
    "    \n",
    "    if EEGdevice == 7:\n",
    "        channels = EEGdata.columns[1:8]\n",
    "    elif EEGdevice == 8:\n",
    "        channels = EEGdata.columns[0:8]\n",
    "\n",
    "    epochs = []\n",
    "    epochs_norm = []\n",
    "\n",
    "    for movement in range(0,len(move_starts)):\n",
    "        # Data for this movement\n",
    "        t_start = move_starts[movement] - np.round(1.00*fs)\n",
    "        t_end = move_starts[movement] - np.round(0.250*fs)\n",
    "\n",
    "        # Baseline\n",
    "        restOfInt = np.max(np.where(rest_starts < move_starts[movement]))\n",
    "        tb_start = rest_starts[restOfInt]\n",
    "        tb_end = rest_ends[restOfInt]\n",
    "\n",
    "        baseline = EEGdata.loc[tb_start:tb_end][channels]\n",
    "\n",
    "        # Store epoch\n",
    "        tmp = (EEGdata.loc[t_start:t_end][channels] - np.mean(baseline))/np.std(baseline)\n",
    "        epochs_norm.append(tmp)\n",
    "        epochs.append(EEGdata.loc[t_start:t_end][channels])\n",
    "\n",
    "    return epochs, epochs_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OrganizeTrials(behavioralData, hasBaseline):\n",
    "    \"\"\"\n",
    "    Organizes trials\n",
    "    \"\"\"\n",
    "    \n",
    "    # When target was to the left\n",
    "    trialL = np.where(behavioralData['target_x'] < behavioralData['player_x'])\n",
    "    \n",
    "    # When target was to the right\n",
    "    trialR = np.where(behavioralData['target_x'] > behavioralData['player_x'])\n",
    "    \n",
    "    # Create a single list that includes which trial is which (L = 0, R = 1)\n",
    "    trial_type = np.zeros([1,len(behavioralData['score'])])\n",
    "    trial_type[0][trialL] = 0\n",
    "    trial_type[0][trialR] = 1\n",
    "\n",
    "    trial_type = np.round(trial_type[0])\n",
    "    \n",
    "    # Remove trials if no baseline\n",
    "    for movement in range(0,len(hasBaseline)):\n",
    "        if hasBaseline[movement] is False:\n",
    "            trial_type = np.delete(trial_type, movement)\n",
    "            \n",
    "    return trial_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeaturesBCI(epochs, num_of_movements, channelsToUse, ds_factor):\n",
    "    \"\"\"\n",
    "    Extract signal features of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the summed delta power for each trial\n",
    "    alpha_power = dict.fromkeys(channelsToUse)\n",
    "    beta_power = dict.fromkeys(channelsToUse)\n",
    "    ds_f = ds_factor # downsampling factor\n",
    "\n",
    "    for chanOfInt in channelsToUse:\n",
    "        tmp_alpha = list()\n",
    "        tmp_beta = list()\n",
    "\n",
    "        for movement in range(0, num_of_movements):\n",
    "            f, Pxx_den = signal.welch(signal.decimate(epochs[movement][chanOfInt],ds_f), fs/ds_f, scaling='spectrum')\n",
    "            alpha_idx = np.where(np.logical_and(np.round(f) > 8, np.round(f) <= 12))\n",
    "            tmp_alpha.append(np.sum(Pxx_den[alpha_idx]))\n",
    "\n",
    "            beta_idx = np.where(np.logical_and(np.round(f) > 13, np.round(f) <= 30))\n",
    "            tmp_beta.append(np.sum(Pxx_den[beta_idx]))\n",
    "\n",
    "        alpha_power[chanOfInt] = tmp_alpha\n",
    "        beta_power[chanOfInt] = tmp_beta\n",
    "    \n",
    "    return alpha_power, beta_power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for working with error (ErrPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EpochErrorData(EEGdata, fs, EEGdevice, t_trial_start):\n",
    "    \"\"\"\n",
    "    This function epochs the data\n",
    "    \"\"\"\n",
    "    if EEGdevice == 7:\n",
    "        channels = EEGdata.columns[1:8]\n",
    "    elif EEGdevice == 8:\n",
    "        channels = EEGdata.columns[0:8]\n",
    "\n",
    "    epochs = []\n",
    "\n",
    "    for trial in range(0,len(t_trial_start)):\n",
    "        t_start = t_trial_start[trial] - np.round(0  * fs)\n",
    "        t_end = t_trial_start[trial] + np.round(0.600 * fs)\n",
    "\n",
    "        # Baseline\n",
    "        tb_start = t_trial_start[trial] - np.round(0.700 * fs)\n",
    "        tb_end = t_trial_start[trial] - np.round(0.100 * fs)\n",
    "        baseline = EEGdata.loc[tb_start:tb_end][channels]\n",
    "\n",
    "        # Store epoch\n",
    "        tmp = (EEGdata.loc[t_start:t_end][channels] - np.mean(baseline))/np.std(baseline)\n",
    "        epochs.append(tmp)\n",
    "    \n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractErrorFeatures(epochs, num_of_trials, error_template, correct_template, featureType):\n",
    "    \"\"\"\n",
    "    Extract signal features of interest\n",
    "    featureType:    'template' or 'frequency'. 'template' returns features based on the template projection values\n",
    "                    for individual epochs with the error and correct templates. 'frequency' returns features that\n",
    "                    are just delta and theta power for each channel for the epochs\n",
    "    \"\"\"\n",
    "    \n",
    "    if featureType in ['template','Template','TEMPLATE','t','T','projection','Projection','PROJECTION','p','P']:\n",
    "        # template_projection[chanOfInt] will have two columns\n",
    "        # col 1: how well the trial signal matches with the error signal template\n",
    "        # col 2: how well the trial signal matches with the correct signal template\n",
    "        projections_all = dict()\n",
    "        channelsToUse = error_template.keys()\n",
    "\n",
    "        for chanOfInt in channelsToUse:\n",
    "            projections = np.zeros([2, num_of_trials])\n",
    "            for trial in range(0, num_of_trials):\n",
    "                # Individual epoch (normalized)\n",
    "                tmp = epochs_norm[trial][chanOfInt]\n",
    "                a = tmp\n",
    "\n",
    "                # Template waveform for error (normalized)\n",
    "                tmp0 = error_template[chanOfInt]\n",
    "                tmp_norm = (tmp0 - np.mean(tmp0))/np.std(tmp0)\n",
    "                b = tmp_norm\n",
    "\n",
    "                # Template waveform for correct (normalized)\n",
    "                tmp = correct_template[chanOfInt]\n",
    "                tmp_norm = (tmp - np.mean(tmp0))/np.std(tmp0)\n",
    "                c = tmp_norm\n",
    "\n",
    "                # Store sum of convolutions\n",
    "\n",
    "                projections[0][trial] = np.sum(np.convolve(a,b,'same'))\n",
    "                projections[1][trial] = np.sum(np.convolve(a,c,'same'))\n",
    "\n",
    "            projections_all[chanOfInt] = projections\n",
    "        \n",
    "        # Organize the features\n",
    "        channels = list(projections_all.keys())\n",
    "        num_of_features = np.shape(projections_all['Cz'])[0] * len(channels)\n",
    "        channels_full = list(projections_all.keys()) * 2\n",
    "        num_of_trials = np.shape(projections_all['Cz'])[1]\n",
    "\n",
    "        features = np.zeros([num_of_features, num_of_trials])\n",
    "\n",
    "        for trial in range(0, num_of_trials):\n",
    "            # Error trials are 0 to num_of_features//2, and correct trials are num_of_features//2 to num_of_features\n",
    "            for feature in range(0, num_of_features):\n",
    "                features[feature, trial] = projections_all[channels_full[feature]][0][trial]\n",
    "            \n",
    "    elif featureType in ['frequency','Frequency','FREQUENCY','f','F']:\n",
    "        channelsToUse = error_template.keys()\n",
    "        delta_power = dict.fromkeys(channelsToUse)\n",
    "        theta_power = dict.fromkeys(channelsToUse)\n",
    "        ds_f = 1 # downsampling factor\n",
    "\n",
    "        for chanOfInt in channelsToUse:\n",
    "            tmp_delta = list()\n",
    "            tmp_theta = list()\n",
    "\n",
    "            for trial in range(0, num_of_trials):\n",
    "                f, Pxx_den = signal.welch(signal.decimate(epochs_norm[trial][chanOfInt],ds_f), fs/ds_f, scaling='spectrum')\n",
    "                delta_idx = np.where(np.round(f) <= 4)\n",
    "                tmp_delta.append(np.sum(Pxx_den[delta_idx]))\n",
    "\n",
    "                theta_idx = np.where(np.logical_and(np.round(f) > 4, np.round(f) <= 7))\n",
    "                tmp_theta.append(np.sum(Pxx_den[theta_idx]))\n",
    "\n",
    "            delta_power[chanOfInt] = tmp_delta\n",
    "            theta_power[chanOfInt] = tmp_theta\n",
    "            \n",
    "        # Organize the features\n",
    "        num_of_examples = len(delta_power['Cz'])\n",
    "        num_of_features = len(delta_power.keys()) + len(theta_power.keys()) \n",
    "        features = np.zeros([num_of_features, num_of_examples])\n",
    "\n",
    "        # Get all channels in one list to loop through\n",
    "        feature_channels = np.concatenate([np.asarray(list(delta_power.keys())),np.asarray(list(theta_power.keys()))])\n",
    "\n",
    "        for i in range(0, num_of_examples):\n",
    "            for j in range(0, num_of_features//2):\n",
    "                features[j, i] = delta_power[feature_channels[j]][i]\n",
    "            for j in range(num_of_features//2, num_of_features):\n",
    "                features[j, i] = theta_power[feature_channels[j]][i]\n",
    "\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfidenceScoreExamples(X, y, EEGdata, epochs_norm, EEGdevice, fs, num_of_movements, move_starts, trial_type):\n",
    "    \"\"\"\n",
    "    This is the function that does the confidence scoring based on error detection and attention\n",
    "    \"\"\"\n",
    "    # Load the error detection model and see what featureType it used (frequency or template projections)\n",
    "    models = glob.glob('Models/' + subjID + '_Error_classifier_*')\n",
    "    model_file = models[-1] # load the most recent model\n",
    "    clf_error = pickle.load(open(model_file, 'rb'))\n",
    "    print(model_file)\n",
    "    print(clf_error)\n",
    "\n",
    "    models_data_list = glob.glob('Models/' + subjID + '_data_for_Error_classifier_*')\n",
    "    models_data = models_data_list[-1] # load the most recent model\n",
    "    loaded_data = np.load(models_data)\n",
    "    featureType = loaded_data['featureType']\n",
    "    \n",
    "    # Load templates if applicable\n",
    "    error_template = loaded_data['error_template'].tolist()\n",
    "    correct_template = loaded_data['correct_template'].tolist()\n",
    "\n",
    "    # Create new epochs for error detection\n",
    "    epochs = EpochErrorData(EEGdata, fs, EEGdevice, move_starts)\n",
    "    features = ExtractErrorFeatures(epochs, num_of_movements, error_template, correct_template, featureType)\n",
    "    features = features.T\n",
    "    \n",
    "    # Scale the features\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    \n",
    "    # Detect error\n",
    "    preds_error = clf_error.predict(features) # is there an ErrP or not? 1 = yes ErrP, 0 = no ErrP\n",
    "    preds_error_proba = clf_error.predict_proba(features) # what is the prob of there being an ErrP?\n",
    "    \n",
    "    # Confidence in the prediction of error\n",
    "    prob_error = (preds_error_proba[:,1] * preds_error)\n",
    "\n",
    "    # Confidence in the prediction of no error\n",
    "    prob_no_error = preds_error_proba[:,0] * (1-preds_error)\n",
    "    \n",
    "    # Get values for attention\n",
    "    attention_alpha, attention_beta = ExtractFeaturesBCI(epochs_norm, num_of_movements, ['Pz'], 1)\n",
    "    epochs_rest, epochs_rest_norm = GetRestEpochsBCI(EEGdata, rest_starts, rest_ends)\n",
    "    attention_alpha_rest_norm, attention_beta_rest_norm = ExtractFeaturesBCI(epochs_rest_norm, len(epochs_rest), ['Pz'], 1)\n",
    "    beta_threshold = np.mean(attention_beta_rest_norm['Pz'])-(2*np.std(attention_beta_rest_norm['Pz']))\n",
    "    distance_from_threshold = (attention_beta['Pz']-beta_threshold)/np.max(attention_beta_rest_norm['Pz'])\n",
    "\n",
    "    # Confidence the epoch is correct\n",
    "    w_a = 0.5\n",
    "    CS_pre_scale = ((prob_no_error - prob_error + 1) - (w_a*distance_from_threshold))/2\n",
    "    CS = (CS_pre_scale - np.min(CS_pre_scale))/(np.max(CS_pre_scale)-np.min(CS_pre_scale))\n",
    "    \n",
    "    \"\"\"\n",
    "    Also return true label stuff\n",
    "    \"\"\"\n",
    "    # Also return true label scores\n",
    "    # Load the error detection model and see what featureType it used (frequency or template projections)\n",
    "    models = glob.glob('Models/' + subjID + '_MI_classifier_*')\n",
    "    model_file = models[-1] # load the most recent model\n",
    "    clf_MI = pickle.load(open(model_file, 'rb'))\n",
    "\n",
    "    preds_MI = clf_MI.predict(X)\n",
    "    \n",
    "    # trial_type 0 is L, trial_type 1 is R, and TL 1 is high confidence (correct), and TL 0 is low confidence (error)\n",
    "    TL = list()\n",
    "    for trial in range(0, len(trial_type)):\n",
    "        if trial_type[trial] == 0:\n",
    "            if preds_MI[trial] == 0:\n",
    "                TL.append(1)\n",
    "            else:\n",
    "                TL.append(0)\n",
    "        elif trial_type[trial] == 1:\n",
    "            if preds_MI[trial] == 1:\n",
    "                TL.append(1)\n",
    "            else:\n",
    "                TL.append(0)\n",
    "\n",
    "    return CS, TL, preds_MI, preds_error, preds_error_proba, epochs, features, clf_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetrainDecoder(clf, CS, threshold, X_old, y_old, X_new, y_new, adaptationType):\n",
    "    \"\"\"\n",
    "    Retrains the decoder on ALL the previous data plus what you decided to add in with high confidence scores\n",
    "    \n",
    "    clf: your preloaded model (most recent version)\n",
    "    CS: confidence scores (if true labels, use TL instead of CS)\n",
    "    X_old: your preloaded model data (X)\n",
    "    y_old: your preloaded model data (y)\n",
    "    X_new: your new motor features\n",
    "    y_new: your new labels\n",
    "    \"\"\"\n",
    "    # Concatenate old X and y with new X and y that have a high enough confidence score\n",
    "    aboveThreshold = np.where(CS>threshold)\n",
    "    \n",
    "    X = np.concatenate((X_old, X_new[aboveThreshold]), axis=0)\n",
    "    y = np.concatenate((y_old, np.asarray(y_new)[aboveThreshold]), axis=0)\n",
    "    \n",
    "    # preprocess dataset, split into training and test part\n",
    "    args = np.arange(len(X))\n",
    "    np.random.shuffle(args)\n",
    "    X = [X[i] for i in args]\n",
    "    y = [y[i] for i in args]\n",
    "    X_not_scaled = X\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Fit the model\n",
    "    clf.fit(X,y)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Split into train and test for evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Fit the model\n",
    "    clf = grid.best_estimator_\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    print(grid.best_estimator_)\n",
    "    print('-----------')\n",
    "    print('score: ' + str(score))\n",
    "    print(confusion_matrix(y_test, clf.predict(X_test)))\n",
    "    print('-----------')\n",
    "    \"\"\"\n",
    "    \n",
    "    return clf, X, X_not_scaled, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveDecoderAndData(clf, X, X_not_scaled, y, subjID):\n",
    "    \"\"\"\n",
    "    Save the decoder and the data it was trained/tested on\n",
    "    \"\"\"\n",
    "    time_to_save = datetime.datetime.now().isoformat()\n",
    "    time_to_save = time_to_save.replace('T','-')\n",
    "    time_to_save = time_to_save.replace(':','-')\n",
    "    \n",
    "    model = clf\n",
    "    model_file = 'Models/' + subjID + '_MI_classifier_' + time_to_save[:19] + '.sav'\n",
    "    pickle.dump(model, open(model_file, 'wb'))\n",
    "    \n",
    "    filepath_export_data = 'Models/' + subjID + '_data_for_MI_classifier_' + time_to_save[:19] + '.npz'\n",
    "    np.savez_compressed(filepath_export_data, X=X, X_not_scaled=X_not_scaled, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to work with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRestEpochsBCI(EEGdata, rest_starts, rest_ends):\n",
    "    \"\"\"\n",
    "    This function returns the rest (ITI) epochs that were used for baseline normalization in the BCI\n",
    "    \"\"\" \n",
    "    if EEGdevice == 7:\n",
    "        channels = EEGdata.columns[1:8]\n",
    "    elif EEGdevice == 8:\n",
    "        channels = EEGdata.columns[0:8]\n",
    "\n",
    "    epochs = []\n",
    "    epochs_norm = []\n",
    "\n",
    "    for rest in range(0,len(rest_starts)):\n",
    "        # Rest periods\n",
    "        t_start = rest_starts[rest]\n",
    "        t_end = rest_ends[rest]\n",
    "        rest_epoch = EEGdata.loc[t_start:t_end][channels]\n",
    "        \n",
    "        # Use previous data to normalize (using -10 to -2 seconds to get pure MI action)\n",
    "        tb_start = rest_starts[rest] - np.round(10.00 * fs)\n",
    "        tb_end = rest_starts[rest] - np.round(2.00 * fs)\n",
    "        baseline = EEGdata.loc[tb_start:tb_end][channels]\n",
    "\n",
    "        # Store epoch\n",
    "        tmp = (rest_epoch - np.mean(baseline))/np.std(baseline)\n",
    "        epochs.append(rest_epoch)\n",
    "        epochs_norm.append(tmp)\n",
    "\n",
    "    return epochs, epochs_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadModel_MI(subjID, run_number=0):\n",
    "    \"\"\"\n",
    "    This function loads the most recent motor imagery classifier\n",
    "    for this subject by default. Current run minus 1.\n",
    "    \n",
    "    You may also select which number model (from original to most recent)\n",
    "    by using a value from 0 (original) to 4 (most recent)\n",
    "    \"\"\"\n",
    "    run_number = run_number - 1\n",
    "    # Load latest model and its associated data\n",
    "    models = glob.glob('Models/' + subjID + '_MI_classifier_*')\n",
    "    \n",
    "    # Throw exception if model number is outside range of existing models\n",
    "    if run_number > len(models):\n",
    "        raise ValueError('Please select a valid model number')\n",
    "    \n",
    "    model_file = models[run_number] # load the most recent model\n",
    "    print('Selecting model: ' + model_file)\n",
    "    clf = pickle.load(open(model_file, 'rb'))\n",
    "\n",
    "    models_data_list = glob.glob('Models/' + subjID + '_data_for_MI_classifier_*')\n",
    "    models_data = models_data_list[run_number] # load the most recent model\n",
    "    MI_data = np.load(models_data)\n",
    "    X_loaded = MI_data['X_not_scaled']\n",
    "    y_loaded = MI_data['y']\n",
    "    \n",
    "    return clf, X_loaded, y_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables to Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the BCI data\n",
    "subjID = 'b12a46'\n",
    "subject_group = 1\n",
    "EEGdevice = 8 # 7 for DSI-7, 8 for Enobio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load latest model and its associated data\n",
    "BCI_files = glob.glob('SaveData/*' + subjID + '_BCI.easy')\n",
    "num_of_runs = len(BCI_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected number of BCI runs: 5\n"
     ]
    }
   ],
   "source": [
    "# Check that this is correct\n",
    "print('Detected number of BCI runs: ' + str(num_of_runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop it to run automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting BCI EEG file: SaveData\\20190206095241_b12a46_BCI.easy\n",
      "Selecting BCI behavioral file: SaveData\\BCI_b12a46_R1.csv\n",
      "Skipping N/A\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=141223\n",
      "    Range : 0 ... 141222 =      0.000 ...   282.444 secs\n",
      "Ready.\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "l_trans_bandwidth chosen to be 1.0 Hz\n",
      "h_trans_bandwidth chosen to be 10.0 Hz\n",
      "Filter length of 1651 samples (3.302 sec) selected\n",
      "Selecting model: Models\\b12a46_MI_classifier_2019-02-06-09-51-18.sav\n",
      "Models\\b12a46_Error_classifier_2019-02-06-10-23-55.sav\n",
      "MLPClassifier(activation='relu', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples: 94\n",
      "Percent of correctly scored examples: 46.808510638297875%\n",
      "----------------\n",
      "Confusion Matrix for Error Classification (not MI)\n",
      "[[35  5]\n",
      " [45  9]]\n",
      "----------------\n",
      "Selecting BCI EEG file: SaveData\\20190206095756_b12a46_BCI.easy\n",
      "Selecting BCI behavioral file: SaveData\\BCI_b12a46_R2.csv\n",
      "Skipping N/A\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=139256\n",
      "    Range : 0 ... 139255 =      0.000 ...   278.510 secs\n",
      "Ready.\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "l_trans_bandwidth chosen to be 1.0 Hz\n",
      "h_trans_bandwidth chosen to be 10.0 Hz\n",
      "Filter length of 1651 samples (3.302 sec) selected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting model: Models\\b12a46_MI_classifier_2019-02-06-11-07-52.sav\n",
      "Models\\b12a46_Error_classifier_2019-02-06-10-23-55.sav\n",
      "MLPClassifier(activation='relu', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples: 109\n",
      "Percent of correctly scored examples: 50.45871559633027%\n",
      "----------------\n",
      "Confusion Matrix for Error Classification (not MI)\n",
      "[[41  8]\n",
      " [46 14]]\n",
      "----------------\n",
      "Selecting BCI EEG file: SaveData\\20190206100259_b12a46_BCI.easy\n",
      "Selecting BCI behavioral file: SaveData\\BCI_b12a46_R3.csv\n",
      "Skipping N/A\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=130832\n",
      "    Range : 0 ... 130831 =      0.000 ...   261.662 secs\n",
      "Ready.\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "l_trans_bandwidth chosen to be 1.0 Hz\n",
      "h_trans_bandwidth chosen to be 10.0 Hz\n",
      "Filter length of 1651 samples (3.302 sec) selected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting model: Models\\b12a46_MI_classifier_2019-02-06-11-07-54.sav\n",
      "Models\\b12a46_Error_classifier_2019-02-06-10-23-55.sav\n",
      "MLPClassifier(activation='relu', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples: 102\n",
      "Percent of correctly scored examples: 50.0%\n",
      "----------------\n",
      "Confusion Matrix for Error Classification (not MI)\n",
      "[[30 12]\n",
      " [39 21]]\n",
      "----------------\n",
      "Selecting BCI EEG file: SaveData\\20190206100731_b12a46_BCI.easy\n",
      "Selecting BCI behavioral file: SaveData\\BCI_b12a46_R4.csv\n",
      "Skipping N/A\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=140705\n",
      "    Range : 0 ... 140704 =      0.000 ...   281.408 secs\n",
      "Ready.\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "l_trans_bandwidth chosen to be 1.0 Hz\n",
      "h_trans_bandwidth chosen to be 10.0 Hz\n",
      "Filter length of 1651 samples (3.302 sec) selected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting model: Models\\b12a46_MI_classifier_2019-02-06-11-07-56.sav\n",
      "Models\\b12a46_Error_classifier_2019-02-06-10-23-55.sav\n",
      "MLPClassifier(activation='relu', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples: 95\n",
      "Percent of correctly scored examples: 41.05263157894737%\n",
      "----------------\n",
      "Confusion Matrix for Error Classification (not MI)\n",
      "[[27  7]\n",
      " [49 12]]\n",
      "----------------\n",
      "Selecting BCI EEG file: SaveData\\20190206101239_b12a46_BCI.easy\n",
      "Selecting BCI behavioral file: SaveData\\BCI_b12a46_R5.csv\n",
      "Skipping N/A\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=136848\n",
      "    Range : 0 ... 136847 =      0.000 ...   273.694 secs\n",
      "Ready.\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "l_trans_bandwidth chosen to be 1.0 Hz\n",
      "h_trans_bandwidth chosen to be 10.0 Hz\n",
      "Filter length of 1651 samples (3.302 sec) selected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting model: Models\\b12a46_MI_classifier_2019-02-06-11-07-58.sav\n",
      "Models\\b12a46_Error_classifier_2019-02-06-10-23-55.sav\n",
      "MLPClassifier(activation='relu', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "Total number of examples: 107\n",
      "Percent of correctly scored examples: 43.925233644859816%\n",
      "----------------\n",
      "Confusion Matrix for Error Classification (not MI)\n",
      "[[35 12]\n",
      " [48 12]]\n",
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Users\\nile\\Anaconda3\\envs\\eeg\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    }
   ],
   "source": [
    "# Run adaptation for all runs except the last one\n",
    "for runOfInt in range(1, num_of_runs+1-1):\n",
    "    # Find BCI file names\n",
    "    filename_eeg, filename_behavioral = FindBCIFiles(subjID, runOfInt)\n",
    "\n",
    "    # Load EEG data\n",
    "    EEGdata, fs, fs_accel = LoadEEGData(filename_eeg, EEGdevice)\n",
    "\n",
    "    # Load behavioral data\n",
    "    behavioralData = LoadBehavioralDataBCI(filename_behavioral)\n",
    "\n",
    "    # Sync up trigger pulses\n",
    "    num_of_trials, num_of_movements, move_starts, hasBaseline, rest_starts, rest_ends = SyncTriggerPulsesBCI(EEGdata, EEGdevice, fs, behavioralData)\n",
    "\n",
    "    # Clean the data\n",
    "    EEGdata_orig = EEGdata.copy()\n",
    "    lf = 1\n",
    "    hf = 40\n",
    "\n",
    "    if EEGdevice == 7:\n",
    "        channels = EEGdata.columns[1:8]\n",
    "    elif EEGdevice == 8:\n",
    "        channels = EEGdata.columns[0:8]\n",
    "\n",
    "    # Format our data into an mne-friendly format\n",
    "    ch_types = ['eeg']*len(channels)\n",
    "    info = mne.create_info(ch_names=list(channels), sfreq=fs, ch_types=ch_types)\n",
    "    rawData = EEGdata[channels].values\n",
    "    rawData = np.transpose(rawData)\n",
    "    raw = mne.io.array.RawArray(rawData, info)\n",
    "    raw.set_montage(mne.channels.read_montage(kind='standard_1020'))\n",
    "    raw.filter(l_freq=lf, h_freq=hf)\n",
    "\n",
    "    # Make a copy of the original data just in case\n",
    "    EEGdata[channels] = raw.get_data().T\n",
    "\n",
    "    # Epoch the data\n",
    "    epochs, epochs_norm = EpochBCIData(EEGdata, move_starts, rest_starts, rest_ends)\n",
    "\n",
    "    # Organize trial types\n",
    "    trial_type = OrganizeTrials(behavioralData, hasBaseline)\n",
    "\n",
    "    # Get signal features\n",
    "    alpha_power, beta_power = ExtractFeaturesBCI(epochs_norm, num_of_movements, ['C3','C4'], 1)\n",
    "    motor_features = [alpha_power['C3'], alpha_power['C4'], beta_power['C3'], beta_power['C4']]\n",
    "    motor_features = np.transpose(motor_features)\n",
    "\n",
    "    # Load latest model and its associated data \n",
    "    MI_model, X_loaded_MI, y_loaded_MI = LoadModel_MI(subjID, runOfInt)\n",
    "\n",
    "    # Choose which examples to keep through confidence scoring\n",
    "    X_new = motor_features\n",
    "    y_new = trial_type\n",
    "\n",
    "    CS, TL, preds_MI, preds_error, preds_error_proba, epochs, features, clf_error = ConfidenceScoreExamples(X_new, y_new, EEGdata, epochs_norm, EEGdevice, fs, num_of_movements, move_starts, trial_type)\n",
    "\n",
    "    # clf_error: our ErrP classifier\n",
    "    # TL: true labels for the performance monitoring epochs in this BCI data\n",
    "    # features: the features for the ErrP classifier for these performance monitoring epochs\n",
    "\n",
    "    print('Total number of examples: ' + str(len(features)))\n",
    "    print('Percent of correctly scored examples: ' + str(clf_error.score(features, TL)*100) + '%')\n",
    "    print('----------------')\n",
    "    print('Confusion Matrix for Error Classification (not MI)')\n",
    "    print(confusion_matrix(TL, clf_error.predict(features)))\n",
    "    print('----------------')\n",
    "\n",
    "    # Retrain\n",
    "    adaptationType = 'CS' # either 'CS' for confidence score, or 'TL' for true label\n",
    "    threshold = 0.7\n",
    "    clf, X, X_not_scaled, y = RetrainDecoder(MI_model, CS, threshold, X_loaded_MI, y_loaded_MI, motor_features, trial_type, adaptationType)\n",
    "\n",
    "    # Save decoder and data it was trained/tested on\n",
    "    SaveDecoderAndData(clf, X, X_not_scaled, y, subjID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
