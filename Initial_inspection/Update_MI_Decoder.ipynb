{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Motor Imagery Decoder\n",
    "Use this clean notebook to load a pre-existing model and associated data, load new data, and re-train the decoder using all the data deemed appropriate for inclusion.\n",
    "\n",
    "Nile Wilson 2019.01.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy import signal\n",
    "from mne.filter import filter_data\n",
    "\n",
    "import scipy.signal as scisig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "import csv\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadEEGData(filename, EEGdevice):\n",
    "    \"\"\" This function converts a single .easy file (from NIC2) to an easy-to-use dataframe.\n",
    "    Uses both the .easy file and .info file (containing metadata)\n",
    "    \n",
    "    ---- Input ----\n",
    "    filename: string containing the .easy filepath\n",
    "    \n",
    "    ---- Output ----\n",
    "    df: dataframe containing all the EEG, accelerometer, and event marker data\n",
    "    fs: sampling rate for the EEG data (Hz)\n",
    "    fs_accel: sampling rate for the accelerometer data (Hz)\n",
    "    \n",
    "    \"\"\"\n",
    "    if EEGdevice == 7:\n",
    "        x = 1\n",
    "    elif EEGdevice == 8:\n",
    "        # Read in the .easy file\n",
    "        df = pd.read_csv(filename, delimiter='\\t', header=None)\n",
    "\n",
    "        # Get metadata from the .info file\n",
    "        fname = filename[:-5] + '.info'\n",
    "        with open(fname) as f:\n",
    "            content = f.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "\n",
    "        # Get the channel names\n",
    "        channel_info = [x for x in content if 'Channel ' in x]\n",
    "        channel_names = []\n",
    "        for ch in range(len(channel_info)):\n",
    "            channel_names.append(channel_info[ch].split(': ')[1])\n",
    "\n",
    "        channel_names.append('X')\n",
    "        channel_names.append('Y')\n",
    "        channel_names.append('Z')\n",
    "        channel_names.append('STI 014')\n",
    "        channel_names.append('DateTime')\n",
    "\n",
    "        # Get sampling rates\n",
    "        sampling_rates = [x for x in content if 'sampling rate: ' in x]\n",
    "        fs_all = []\n",
    "        for freq in range(len(sampling_rates)):\n",
    "            fs_all.append(float(sampling_rates[freq].split(': ')[1].split(' ')[0]))\n",
    "\n",
    "        # Store sampling rates\n",
    "        fs = fs_all[0]\n",
    "        fs_accel = fs_all[1]\n",
    "\n",
    "        # Assign the column names\n",
    "        df.columns = channel_names\n",
    "    \n",
    "    # Return dataframe and sampling rates\n",
    "    return df, fs, fs_accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadBehavioralData(filename_behavioral):\n",
    "    \"\"\"\n",
    "    This function loads behavioral data for the motor screening task and formats it to use in this script\n",
    "    \"\"\"\n",
    "    behavioralData = pd.read_csv(filename_behavioral, ',')\n",
    "    behavioralData = behavioralData.transpose()\n",
    "    behavioralHeader = behavioralData.iloc[0]\n",
    "    behavioralData = behavioralData.iloc[2:]\n",
    "    behavioralData.columns = behavioralHeader\n",
    "    \n",
    "    return behavioralData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SyncTriggerPulses(EEGdata, EEGdevice, fs, behavioralData):\n",
    "    \"\"\"\n",
    "    This function returns the indices for events of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    if EEGdevice == 7:\n",
    "        print('Put code here')\n",
    "    elif EEGdevice == 8:\n",
    "        # Store where the values in trigger are equal to 8 (the audio trigger input channel number)\n",
    "        index_trigger = np.where(EEGdata['STI 014']!=0)\n",
    "        index_trigger = index_trigger[0]\n",
    "        \n",
    "        # Check number of trials\n",
    "        num_of_trials = behavioralData.shape[0]\n",
    "        if num_of_trials > len(index_trigger):\n",
    "            num_of_trials = num_of_trials - 1\n",
    "            num_trials_removed = 1\n",
    "        else:\n",
    "            num_trials_removed = 0\n",
    "        \n",
    "        trialLength = int(behavioralData['trialLength'][0])\n",
    "\n",
    "        # Get trial timing\n",
    "        t_trial_start = list()\n",
    "        t_trial_end = list()\n",
    "\n",
    "        # Creating lists of all trigger start and end locations\n",
    "        for i in range(0,num_of_trials):\n",
    "            t_trial_start.append(index_trigger[i])\n",
    "            t_trial_end.append(index_trigger[i] + int(trialLength*fs))\n",
    "\n",
    "        # Save rest period epochs as well as trials for comparison\n",
    "        t_rest_start = list()\n",
    "        t_rest_end = list()\n",
    "\n",
    "        for i in range(num_of_trials-1):\n",
    "            t_rest_start.append(t_trial_end[i])\n",
    "            t_rest_end.append(t_trial_start[i+1])\n",
    "    \n",
    "    return num_of_trials, t_trial_start, t_trial_end, t_rest_start, t_rest_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EpochData(EEGdata, t_trial_start, t_trial_end):\n",
    "    \"\"\"\n",
    "    This function epochs the data\n",
    "    \"\"\"\n",
    "    \n",
    "    if EEGdevice == 7:\n",
    "        channels = EEGdata.columns[1:8]\n",
    "    elif EEGdevice == 8:\n",
    "        channels = EEGdata.columns[0:7]\n",
    "    \n",
    "    epochs = []\n",
    "    epochs_norm = []\n",
    "\n",
    "    for trial in range(0,len(t_trial_start)):\n",
    "        t_start = t_trial_start[trial]\n",
    "        t_end = t_trial_end[trial]\n",
    "\n",
    "        # Baseline\n",
    "        if trial == 0:\n",
    "            tb_start = t_trial_start[trial] - np.round(1.5*fs)\n",
    "            tb_end = t_trial_start[trial]\n",
    "        else:\n",
    "            tb_start = t_trial_end[trial-1]\n",
    "            tb_end = t_trial_start[trial]\n",
    "            \n",
    "        baseline = EEGdata.loc[tb_start:tb_end][channels]\n",
    "        \n",
    "        # Store epoch\n",
    "        tmp = (EEGdata.loc[t_start:t_end][channels] - np.mean(baseline))/np.std(baseline)\n",
    "        epochs_norm.append(tmp)\n",
    "        epochs.append(EEGdata.loc[t_start:t_end][channels])\n",
    "    \n",
    "    return epochs, epochs_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OrganizeTrials(behavioralData):\n",
    "    \"\"\"\n",
    "    Organizes trials\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create lists for each trial type\n",
    "    trialL = list()\n",
    "    trialR = list()\n",
    "    i = 0\n",
    "\n",
    "    for letter in behavioralData['trialType'][1:]:\n",
    "        if letter == 'L':\n",
    "            trialL.append(i)\n",
    "        elif letter == 'R':\n",
    "            trialR.append(i)\n",
    "        i += 1\n",
    "    \n",
    "    # Create a single list that includes which trial is which (L = 0, R = 1)\n",
    "    trial_type = list()\n",
    "    i = 0\n",
    "\n",
    "    for letter in behavioralData['trialType'][1:]:\n",
    "        if letter == 'L':\n",
    "            trial_type.append(0)\n",
    "        elif letter == 'R':\n",
    "            trial_type.append(1)\n",
    "        i += 1\n",
    "\n",
    "    return trial_type, trialL, trialR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeatures(epochs, num_of_trials, channelsToUse, ds_factor):\n",
    "    \"\"\"\n",
    "    Extract signal features of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the summed delta power for each trial\n",
    "    alpha_power = dict.fromkeys(channelsToUse)\n",
    "    beta_power = dict.fromkeys(channelsToUse)\n",
    "    ds_f = ds_factor # downsampling factor\n",
    "\n",
    "    for chanOfInt in channelsToUse:\n",
    "        tmp_alpha = list()\n",
    "        tmp_beta = list()\n",
    "\n",
    "        for trial in range(0, num_of_trials):\n",
    "            f, Pxx_den = signal.welch(signal.decimate(epochs[trial][chanOfInt],ds_f), fs/ds_f, scaling='spectrum')\n",
    "            alpha_idx = np.where(np.logical_and(np.round(f) > 8, np.round(f) <= 12))\n",
    "            tmp_alpha.append(np.sum(Pxx_den[alpha_idx]))\n",
    "\n",
    "            beta_idx = np.where(np.logical_and(np.round(f) > 13, np.round(f) <= 30))\n",
    "            tmp_beta.append(np.sum(Pxx_den[beta_idx]))\n",
    "\n",
    "        alpha_power[chanOfInt] = tmp_alpha\n",
    "        beta_power[chanOfInt] = tmp_beta\n",
    "    \n",
    "    return alpha_power, beta_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainDecoder(X, y):\n",
    "    \"\"\"\n",
    "    Trains the decoder on ALL the data (does not split into test and train because this is all train)\n",
    "    \"\"\"\n",
    "    # preprocess dataset, split into training and test part\n",
    "    args = np.arange(len(X))\n",
    "    np.random.shuffle(args)\n",
    "    X = [X[i] for i in args]\n",
    "    y = [y[i] for i in args]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "\n",
    "    # Determine model parameters\n",
    "    activations = ['relu','tanh']\n",
    "    alphas = np.logspace(-6, 3, 10)\n",
    "    solvers = ['lbfgs','sgd']\n",
    "    hyper_params = {\"activation\":activations, \"alpha\":alphas, \"solver\":solvers}\n",
    "    grid = GridSearchCV(MLPClassifier(learning_rate='constant', random_state=1), param_grid=hyper_params, cv=KFold(n_splits=5), verbose=True)\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    # Fit the model\n",
    "    clf = grid.best_estimator_\n",
    "    clf.fit(X,y)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Split into train and test for evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Fit the model\n",
    "    clf = grid.best_estimator_\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    print(grid.best_estimator_)\n",
    "    print('-----------')\n",
    "    print('score: ' + str(score))\n",
    "    print(confusion_matrix(y_test, clf.predict(X_test)))\n",
    "    print('-----------')\n",
    "    \"\"\"\n",
    "    \n",
    "    return clf, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveDecoderAndData(clf, X, y, subjID):\n",
    "    \"\"\"\n",
    "    Save the decoder and the data it was trained/tested on\n",
    "    \"\"\"\n",
    "    time_to_save = datetime.datetime.now().isoformat()\n",
    "    time_to_save = time_to_save.replace('T','-')\n",
    "    time_to_save = time_to_save.replace(':','-')\n",
    "    \n",
    "    model = clf\n",
    "    model_file = subjID + '_MI_classifier_' + time_to_save[:19] + '.sav'\n",
    "    pickle.dump(model, open(model_file, 'wb'))\n",
    "    \n",
    "    filepath_export_data = subjID + '_data_for_MI_classifier_' + time_to_save[:19] + '.npz'\n",
    "    np.savez_compressed(filepath_export_data, X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables to Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjID = 'nile'\n",
    "EEGdevice = 8 # 7 for DSI-7, 8 for Enobio\n",
    "filename_eeg = '../data/Enobio/20190109103635_nile_motor_screening_R2.easy'\n",
    "filename_behavioral = '../data/Enobio/nile_Motor_Screening_R2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new EEG data\n",
    "\n",
    "# Load behavioral data that goes with this new EEG data\n",
    "\n",
    "# Clean data\n",
    "\n",
    "# Format to run in classification\n",
    "\n",
    "# Choose which examples to keep through confidence scoring\n",
    "\n",
    "# Load latest model and its associated data\n",
    "\n",
    "# Concatenate new X and y to old X and y (loaded)\n",
    "\n",
    "# Retrain\n",
    "\n",
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And to load\n",
    "loaded_model = pickle.load(open(model_file, 'rb'))\n",
    "print(loaded_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load(filepath_export_data)\n",
    "npzfile.files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
