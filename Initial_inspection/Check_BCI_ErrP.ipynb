{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check BCI ErrPs\n",
    "Use this clean notebook to check the Error-related Potentials (ErrPs) in the BCI data!\n",
    "\n",
    "Nile Wilson 2019.01.29-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy import signal\n",
    "from mne.filter import filter_data\n",
    "\n",
    "import scipy.signal as scisig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "import glob\n",
    "import csv\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING\n",
    "Make sure to change the filepath search locations when making this a function! It currently looks for stuff in the same folder or ../data/nile/, but should be savedata (check capitalization) in the end!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for working with the BCI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadEEGData(filename, EEGdevice):\n",
    "    \"\"\" This function converts a single .easy file (from NIC2) to an easy-to-use dataframe.\n",
    "    Uses both the .easy file and .info file (containing metadata)\n",
    "    \n",
    "    ---- Input ----\n",
    "    filename: string containing the .easy filepath\n",
    "    \n",
    "    ---- Output ----\n",
    "    df: dataframe containing all the EEG, accelerometer, and event marker data\n",
    "    fs: sampling rate for the EEG data (Hz)\n",
    "    fs_accel: sampling rate for the accelerometer data (Hz)\n",
    "    \n",
    "    \"\"\"\n",
    "    if EEGdevice == 7:\n",
    "        x = 1\n",
    "    elif EEGdevice == 8:\n",
    "        # Read in the .easy file\n",
    "        df = pd.read_csv(filename, delimiter='\\t', header=None)\n",
    "\n",
    "        # Get metadata from the .info file\n",
    "        fname = filename[:-5] + '.info'\n",
    "        with open(fname) as f:\n",
    "            content = f.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "\n",
    "        # Get the channel names\n",
    "        channel_info = [x for x in content if 'Channel ' in x]\n",
    "        channel_names = []\n",
    "        for ch in range(len(channel_info)):\n",
    "            channel_names.append(channel_info[ch].split(': ')[1])\n",
    "\n",
    "        channel_names.append('X')\n",
    "        channel_names.append('Y')\n",
    "        channel_names.append('Z')\n",
    "        channel_names.append('STI 014')\n",
    "        channel_names.append('DateTime')\n",
    "\n",
    "        # Get sampling rates\n",
    "        sampling_rates = [x for x in content if 'sampling rate: ' in x]\n",
    "        fs_all = []\n",
    "        for freq in range(len(sampling_rates)):\n",
    "            tmp = sampling_rates[freq].split(': ')[1].split(' ')[0]\n",
    "            if tmp in ['N/A']:\n",
    "                print('Skipping N/A')\n",
    "            else:\n",
    "                fs_all.append(float(sampling_rates[freq].split(': ')[1].split(' ')[0]))\n",
    "\n",
    "        # Store sampling rates\n",
    "        fs = fs_all[0]\n",
    "        fs_accel = fs_all[1]\n",
    "\n",
    "        # Assign the column names\n",
    "        df.columns = channel_names\n",
    "    \n",
    "    # Return dataframe and sampling rates\n",
    "    return df, fs, fs_accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadBehavioralDataBCI(filename_behavioral):\n",
    "    \"\"\"\n",
    "    This function loads behavioral data for the motor screening task and formats it to use in this script\n",
    "    \"\"\"\n",
    "    behavioralData = pd.read_csv(filename_behavioral, ',')\n",
    "    \n",
    "    return behavioralData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SyncTriggerPulsesBCI(EEGdata, EEGdevice, fs, behavioralData):\n",
    "    \"\"\"\n",
    "    This function returns the indices for events of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    if EEGdevice == 7:\n",
    "        print('Put code here')\n",
    "    elif EEGdevice == 8:\n",
    "        # Store where the values in trigger are equal to 8 (the audio trigger input channel number)\n",
    "        index_trigger = np.where(EEGdata['STI 014']!=0)\n",
    "        index_trigger = index_trigger[0]\n",
    "\n",
    "        # Number of trials is greater than number of total pulses sent\n",
    "        # 999 when the task ends\n",
    "        move_left_starts = np.where(EEGdata['STI 014'] == 1)[0]\n",
    "        move_right_starts = np.where(EEGdata['STI 014'] == 2)[0]\n",
    "        rest_starts = np.where(EEGdata['STI 014'] == 3)[0]\n",
    "        rest_ends = np.where(EEGdata['STI 014'] == 4)[0]\n",
    "        \n",
    "        # If the number of rest_starts and rest_ends don't match, drop the extra one\n",
    "        # there should, by default, only be 12 starts and 12 ends\n",
    "\n",
    "        if len(rest_ends) > len(rest_starts):\n",
    "            if rest_ends[0] < rest_starts[0]:\n",
    "                rest_ends = rest_ends[1:]\n",
    "        elif len(rest_ends) < len(rest_starts):\n",
    "            if rest_ends[0] > rest_starts[0]:\n",
    "                rest_starts = rest_starts[1:]\n",
    "        \n",
    "        move_starts = np.sort(np.concatenate((move_left_starts,move_right_starts),0))\n",
    "        total_movements = len(move_starts)\n",
    "\n",
    "        # exclude movements that occur without defined baseline (if you need to get rid of first rest)\n",
    "        hasBaseline = list()\n",
    "        for movement in range(0,len(move_starts)):\n",
    "            hasBaseline.append(True in (rest_starts < move_starts[movement]))\n",
    "\n",
    "        np.where(hasBaseline)\n",
    "        move_starts = move_starts[np.where(hasBaseline)]\n",
    "\n",
    "        # exclude the move lefts and move rights that were thrown out in move_starts\n",
    "        for movement in range(0,total_movements):\n",
    "            if hasBaseline[movement] is False:\n",
    "                # for the left movements\n",
    "                idx_left = np.where(move_left_starts == move_starts[movement])\n",
    "                idx_left = np.asarray(idx_left)\n",
    "                idx_right = np.where(move_right_starts == move_starts[movement])\n",
    "                idx_right = np.asarray(idx_right)\n",
    "\n",
    "                if idx_left.size > 0:\n",
    "                    move_left_starts = np.delete(move_left_starts, idx_left)\n",
    "                if idx_right.size > 0:\n",
    "                    move_right_starts = np.delete(move_right_starts, idx_right)\n",
    "                \n",
    "        num_of_trials = len(rest_starts)\n",
    "        num_of_movements = len(move_left_starts) + len(move_right_starts)\n",
    "    \n",
    "    return num_of_trials, num_of_movements, move_starts, hasBaseline, rest_starts, rest_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EpochBCIData(EEGdata, move_starts, rest_starts, rest_ends):\n",
    "    \"\"\"\n",
    "    This function epochs the data\n",
    "    \"\"\"\n",
    "    \n",
    "    if EEGdevice == 7:\n",
    "        channels = EEGdata.columns[1:8]\n",
    "    elif EEGdevice == 8:\n",
    "        channels = EEGdata.columns[0:8]\n",
    "\n",
    "    epochs = []\n",
    "    epochs_norm = []\n",
    "\n",
    "    for movement in range(0,len(move_starts)):\n",
    "        # Data for this movement\n",
    "        t_start = move_starts[movement] - np.round(1.00*fs)\n",
    "        t_end = move_starts[movement] - np.round(0.250*fs)\n",
    "\n",
    "        # Baseline\n",
    "        restOfInt = np.max(np.where(rest_starts < move_starts[movement]))\n",
    "        tb_start = rest_starts[restOfInt]\n",
    "        tb_end = rest_ends[restOfInt]\n",
    "\n",
    "        baseline = EEGdata.loc[tb_start:tb_end][channels]\n",
    "\n",
    "        # Store epoch\n",
    "        tmp = (EEGdata.loc[t_start:t_end][channels] - np.mean(baseline))/np.std(baseline)\n",
    "        epochs_norm.append(tmp)\n",
    "        epochs.append(EEGdata.loc[t_start:t_end][channels])\n",
    "\n",
    "    return epochs, epochs_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OrganizeTrials(behavioralData, hasBaseline):\n",
    "    \"\"\"\n",
    "    Organizes trials\n",
    "    \"\"\"\n",
    "    \n",
    "    # When target was to the left\n",
    "    trialL = np.where(behavioralData['target_x'] < behavioralData['player_x'])\n",
    "    \n",
    "    # When target was to the right\n",
    "    trialR = np.where(behavioralData['target_x'] > behavioralData['player_x'])\n",
    "    \n",
    "    # Create a single list that includes which trial is which (L = 0, R = 1)\n",
    "    trial_type = np.zeros([1,len(behavioralData['score'])])\n",
    "    trial_type[0][trialL] = 0\n",
    "    trial_type[0][trialR] = 1\n",
    "\n",
    "    trial_type = np.round(trial_type[0])\n",
    "    \n",
    "    # Remove trials if no baseline\n",
    "    for movement in range(0,len(hasBaseline)):\n",
    "        if hasBaseline[movement] is False:\n",
    "            trial_type = np.delete(trial_type, movement)\n",
    "            \n",
    "    return trial_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeaturesBCI(epochs, num_of_movements, channelsToUse, ds_factor):\n",
    "    \"\"\"\n",
    "    Extract signal features of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the summed delta power for each trial\n",
    "    alpha_power = dict.fromkeys(channelsToUse)\n",
    "    beta_power = dict.fromkeys(channelsToUse)\n",
    "    ds_f = ds_factor # downsampling factor\n",
    "\n",
    "    for chanOfInt in channelsToUse:\n",
    "        tmp_alpha = list()\n",
    "        tmp_beta = list()\n",
    "\n",
    "        for movement in range(0, num_of_movements):\n",
    "            f, Pxx_den = signal.welch(signal.decimate(epochs[movement][chanOfInt],ds_f), fs/ds_f, scaling='spectrum')\n",
    "            alpha_idx = np.where(np.logical_and(np.round(f) > 8, np.round(f) <= 12))\n",
    "            tmp_alpha.append(np.sum(Pxx_den[alpha_idx]))\n",
    "\n",
    "            beta_idx = np.where(np.logical_and(np.round(f) > 13, np.round(f) <= 30))\n",
    "            tmp_beta.append(np.sum(Pxx_den[beta_idx]))\n",
    "\n",
    "        alpha_power[chanOfInt] = tmp_alpha\n",
    "        beta_power[chanOfInt] = tmp_beta\n",
    "    \n",
    "    return alpha_power, beta_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainDecoder(X, y):\n",
    "    \"\"\"\n",
    "    Trains the decoder on ALL the data (does not split into test and train because this is all train)\n",
    "    \"\"\"\n",
    "    # preprocess dataset, split into training and test part\n",
    "    args = np.arange(len(X))\n",
    "    np.random.shuffle(args)\n",
    "    X = [X[i] for i in args]\n",
    "    y = [y[i] for i in args]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "\n",
    "    # Determine model parameters\n",
    "    activations = ['relu','tanh']\n",
    "    alphas = np.logspace(-6, 3, 10)\n",
    "    solvers = ['lbfgs','sgd']\n",
    "    hyper_params = {\"activation\":activations, \"alpha\":alphas, \"solver\":solvers}\n",
    "    grid = GridSearchCV(MLPClassifier(learning_rate='constant', random_state=1), param_grid=hyper_params, cv=KFold(n_splits=5), verbose=True)\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    # Fit the model\n",
    "    clf = grid.best_estimator_\n",
    "    clf.fit(X,y)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Split into train and test for evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Fit the model\n",
    "    clf = grid.best_estimator_\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    print(grid.best_estimator_)\n",
    "    print('-----------')\n",
    "    print('score: ' + str(score))\n",
    "    print(confusion_matrix(y_test, clf.predict(X_test)))\n",
    "    print('-----------')\n",
    "    \"\"\"\n",
    "    \n",
    "    return clf, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for working with error (ErrPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EpochErrorData(EEGdata, fs, EEGdevice, t_trial_start):\n",
    "    \"\"\"\n",
    "    This function epochs the data\n",
    "    \"\"\"\n",
    "    if EEGdevice == 7:\n",
    "        channels = EEGdata.columns[1:8]\n",
    "    elif EEGdevice == 8:\n",
    "        channels = EEGdata.columns[0:8]\n",
    "\n",
    "    epochs = []\n",
    "\n",
    "    for trial in range(0,len(t_trial_start)):\n",
    "        t_start = t_trial_start[trial] - np.round(0  * fs)\n",
    "        t_end = t_trial_start[trial] + np.round(0.600 * fs)\n",
    "\n",
    "        # Baseline\n",
    "        tb_start = t_trial_start[trial] - np.round(0.700 * fs)\n",
    "        tb_end = t_trial_start[trial] - np.round(0.100 * fs)\n",
    "        baseline = EEGdata.loc[tb_start:tb_end][channels]\n",
    "\n",
    "        # Store epoch\n",
    "        tmp = (EEGdata.loc[t_start:t_end][channels] - np.mean(baseline))/np.std(baseline)\n",
    "        epochs.append(tmp)\n",
    "    \n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractErrorFeatures(epochs, num_of_trials, error_template, correct_template, featureType):\n",
    "    \"\"\"\n",
    "    Extract signal features of interest\n",
    "    featureType:    'template' or 'frequency'. 'template' returns features based on the template projection values\n",
    "                    for individual epochs with the error and correct templates. 'frequency' returns features that\n",
    "                    are just delta and theta power for each channel for the epochs\n",
    "    \"\"\"\n",
    "    \n",
    "    if featureType in ['template','Template','TEMPLATE','t','T','projection','Projection','PROJECTION','p','P']:\n",
    "        # template_projection[chanOfInt] will have two columns\n",
    "        # col 1: how well the trial signal matches with the error signal template\n",
    "        # col 2: how well the trial signal matches with the correct signal template\n",
    "        projections_all = dict()\n",
    "        channelsToUse = error_template.keys()\n",
    "\n",
    "        for chanOfInt in channelsToUse:\n",
    "            projections = np.zeros([2, num_of_trials])\n",
    "            for trial in range(0, num_of_trials):\n",
    "                # Individual epoch (normalized)\n",
    "                tmp = epochs_norm[trial][chanOfInt]\n",
    "                a = tmp\n",
    "\n",
    "                # Template waveform for error (normalized)\n",
    "                tmp0 = error_template[chanOfInt]\n",
    "                tmp_norm = (tmp0 - np.mean(tmp0))/np.std(tmp0)\n",
    "                b = tmp_norm\n",
    "\n",
    "                # Template waveform for correct (normalized)\n",
    "                tmp = correct_template[chanOfInt]\n",
    "                tmp_norm = (tmp - np.mean(tmp0))/np.std(tmp0)\n",
    "                c = tmp_norm\n",
    "\n",
    "                # Store sum of convolutions\n",
    "\n",
    "                projections[0][trial] = np.sum(np.convolve(a,b,'same'))\n",
    "                projections[1][trial] = np.sum(np.convolve(a,c,'same'))\n",
    "\n",
    "            projections_all[chanOfInt] = projections\n",
    "        \n",
    "        # Organize the features\n",
    "        channels = list(projections_all.keys())\n",
    "        num_of_features = np.shape(projections_all['Cz'])[0] * len(channels)\n",
    "        channels_full = list(projections_all.keys()) * 2\n",
    "        num_of_trials = np.shape(projections_all['Cz'])[1]\n",
    "\n",
    "        features = np.zeros([num_of_features, num_of_trials])\n",
    "\n",
    "        for trial in range(0, num_of_trials):\n",
    "            # Error trials are 0 to num_of_features//2, and correct trials are num_of_features//2 to num_of_features\n",
    "            for feature in range(0, num_of_features):\n",
    "                features[feature, trial] = projections_all[channels_full[feature]][0][trial]\n",
    "            \n",
    "    elif featureType in ['frequency','Frequency','FREQUENCY','f','F']:\n",
    "        channelsToUse = error_template.keys()\n",
    "        delta_power = dict.fromkeys(channelsToUse)\n",
    "        theta_power = dict.fromkeys(channelsToUse)\n",
    "        ds_f = 1 # downsampling factor\n",
    "\n",
    "        for chanOfInt in channelsToUse:\n",
    "            tmp_delta = list()\n",
    "            tmp_theta = list()\n",
    "\n",
    "            for trial in range(0, num_of_trials):\n",
    "                f, Pxx_den = signal.welch(signal.decimate(epochs_norm[trial][chanOfInt],ds_f), fs/ds_f, scaling='spectrum')\n",
    "                delta_idx = np.where(np.round(f) <= 4)\n",
    "                tmp_delta.append(np.sum(Pxx_den[delta_idx]))\n",
    "\n",
    "                theta_idx = np.where(np.logical_and(np.round(f) > 4, np.round(f) <= 7))\n",
    "                tmp_theta.append(np.sum(Pxx_den[theta_idx]))\n",
    "\n",
    "            delta_power[chanOfInt] = tmp_delta\n",
    "            theta_power[chanOfInt] = tmp_theta\n",
    "            \n",
    "        # Organize the features\n",
    "        num_of_examples = len(delta_power['Cz'])\n",
    "        num_of_features = len(delta_power.keys()) + len(theta_power.keys()) \n",
    "        features = np.zeros([num_of_features, num_of_examples])\n",
    "\n",
    "        # Get all channels in one list to loop through\n",
    "        feature_channels = np.concatenate([np.asarray(list(delta_power.keys())),np.asarray(list(theta_power.keys()))])\n",
    "\n",
    "        for i in range(0, num_of_examples):\n",
    "            for j in range(0, num_of_features//2):\n",
    "                features[j, i] = delta_power[feature_channels[j]][i]\n",
    "            for j in range(num_of_features//2, num_of_features):\n",
    "                features[j, i] = theta_power[feature_channels[j]][i]\n",
    "\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfidenceScoreExamples(X, y, EEGdata, EEGdevice, fs, num_of_movements, move_starts, trial_type):\n",
    "    \"\"\"\n",
    "    This is the function that does the confidence scoring based on error detection and attention\n",
    "    \"\"\"\n",
    "    # Load the error detection model and see what featureType it used (frequency or template projections)\n",
    "    models = glob.glob('../data/nile/' + subjID + '_Error_classifier_*')\n",
    "    model_file = models[-1] # load the most recent model\n",
    "    clf_error = pickle.load(open(model_file, 'rb'))\n",
    "    print(model_file)\n",
    "    print(clf_error)\n",
    "\n",
    "    models_data_list = glob.glob('../data/nile/' + subjID + '_data_for_Error_classifier_*')\n",
    "    models_data = models_data_list[-1] # load the most recent model\n",
    "    loaded_data = np.load(models_data)\n",
    "    featureType = loaded_data['featureType']\n",
    "    \n",
    "    # Load templates if applicable\n",
    "    error_template = loaded_data['error_template'].tolist()\n",
    "    correct_template = loaded_data['correct_template'].tolist()\n",
    "\n",
    "    # Create new epochs for error detection\n",
    "    epochs = EpochErrorData(EEGdata, fs, EEGdevice, move_starts)\n",
    "    features = ExtractErrorFeatures(epochs, num_of_movements, error_template, correct_template, featureType)\n",
    "    features = features.T\n",
    "    \n",
    "    # Scale the features\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    \n",
    "    # Detect error\n",
    "    preds_error = clf_error.predict(features) # is there an ErrP or not? 1 = yes ErrP, 0 = no ErrP\n",
    "    preds_error_proba = clf_error.predict_proba(features) # what is the prob of there being an ErrP?\n",
    "    \n",
    "    # Confidence in the prediction of error\n",
    "    prob_error = (preds_error_proba[:,1] * preds_error)\n",
    "\n",
    "    # Confidence in the prediction of no error\n",
    "    prob_no_error = preds_error_proba[:,0] * (1-preds_error)\n",
    "\n",
    "    # Confidence the epoch is correct\n",
    "    CS = (prob_no_error - prob_error + 1)/2\n",
    "    \n",
    "    \"\"\"\n",
    "    Also return true label stuff\n",
    "    \"\"\"\n",
    "    # Also return true label scores\n",
    "    # Load the error detection model and see what featureType it used (frequency or template projections)\n",
    "    models = glob.glob(subjID + '_MI_classifier_*')\n",
    "    model_file = models[-1] # load the most recent model\n",
    "    clf_MI = pickle.load(open(model_file, 'rb'))\n",
    "\n",
    "    preds_MI = clf_MI.predict(X)\n",
    "    \n",
    "    # trial_type 0 is L, trial_type 1 is R, and TL 1 is high confidence (correct), and TL 0 is low confidence (error)\n",
    "    TL = list()\n",
    "    for trial in range(0, len(trial_type)):\n",
    "        if trial_type[trial] == 0:\n",
    "            if preds_MI[trial] == 0:\n",
    "                TL.append(1)\n",
    "            else:\n",
    "                TL.append(0)\n",
    "        elif trial_type[trial] == 1:\n",
    "            if preds_MI[trial] == 1:\n",
    "                TL.append(1)\n",
    "            else:\n",
    "                TL.append(0)\n",
    "\n",
    "    return CS, TL, preds_MI, preds_error, preds_error_proba, epochs, features, clf_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetrainDecoder(clf, CS, threshold, X_old, y_old, X_new, y_new, adaptationType):\n",
    "    \"\"\"\n",
    "    Retrains the decoder on ALL the previous data plus what you decided to add in with high confidence scores\n",
    "    \n",
    "    clf: your preloaded model (most recent version)\n",
    "    CS: confidence scores (if true labels, use TL instead of CS)\n",
    "    X_old: your preloaded model data (X)\n",
    "    y_old: your preloaded model data (y)\n",
    "    X_new: your new motor features\n",
    "    y_new: your new labels\n",
    "    \"\"\"\n",
    "    # Concatenate old X and y with new X and y that have a high enough confidence score\n",
    "    aboveThreshold = np.where(CS>threshold)\n",
    "    \n",
    "    X = np.concatenate((X_old, X_new[aboveThreshold]), axis=0)\n",
    "    y = np.concatenate((y_old, np.asarray(y_new)[aboveThreshold]), axis=0)\n",
    "    \n",
    "    # preprocess dataset, split into training and test part\n",
    "    args = np.arange(len(X))\n",
    "    np.random.shuffle(args)\n",
    "    X = [X[i] for i in args]\n",
    "    y = [y[i] for i in args]\n",
    "    X_not_scaled = X\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Fit the model\n",
    "    clf.fit(X,y)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Split into train and test for evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Fit the model\n",
    "    clf = grid.best_estimator_\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    print(grid.best_estimator_)\n",
    "    print('-----------')\n",
    "    print('score: ' + str(score))\n",
    "    print(confusion_matrix(y_test, clf.predict(X_test)))\n",
    "    print('-----------')\n",
    "    \"\"\"\n",
    "    \n",
    "    return clf, X, X_not_scaled, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveDecoderAndData(clf, X, X_not_scaled, y, subjID):\n",
    "    \"\"\"\n",
    "    Save the decoder and the data it was trained/tested on\n",
    "    \"\"\"\n",
    "    time_to_save = datetime.datetime.now().isoformat()\n",
    "    time_to_save = time_to_save.replace('T','-')\n",
    "    time_to_save = time_to_save.replace(':','-')\n",
    "    \n",
    "    model = clf\n",
    "    model_file = subjID + '_MI_classifier_' + time_to_save[:19] + '.sav'\n",
    "    pickle.dump(model, open(model_file, 'wb'))\n",
    "    \n",
    "    filepath_export_data = subjID + '_data_for_MI_classifier_' + time_to_save[:19] + '.npz'\n",
    "    np.savez_compressed(filepath_export_data, X=X, X_not_scaled=X_not_scaled, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables to Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the BCI data\n",
    "subjID = 'nile'\n",
    "EEGdevice = 8 # 7 for DSI-7, 8 for Enobio\n",
    "filename_eeg = '../data/nile/20190130122905_nile_BCI.easy'\n",
    "filename_behavioral = '../data/nile/BCI_nile_R1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the BCI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping N/A\n",
      "Creating RawArray with float64 data, n_channels=7, n_times=138604\n",
      "    Range : 0 ... 138603 =      0.000 ...   277.206 secs\n",
      "Ready.\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "l_trans_bandwidth chosen to be 1.0 Hz\n",
      "h_trans_bandwidth chosen to be 10.0 Hz\n",
      "Filter length of 1651 samples (3.302 sec) selected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilew\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Users\\nilew\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    }
   ],
   "source": [
    "# Load EEG data\n",
    "EEGdata, fs, fs_accel = LoadEEGData(filename_eeg, EEGdevice)\n",
    "\n",
    "# Load behavioral data\n",
    "behavioralData = LoadBehavioralDataBCI(filename_behavioral)\n",
    "\n",
    "# Sync up trigger pulses\n",
    "num_of_trials, num_of_movements, move_starts, hasBaseline, rest_starts, rest_ends = SyncTriggerPulsesBCI(EEGdata, EEGdevice, fs, behavioralData)\n",
    "\n",
    "# Clean the data\n",
    "EEGdata_orig = EEGdata.copy()\n",
    "lf = 1\n",
    "hf = 40\n",
    "\n",
    "if EEGdevice == 7:\n",
    "    channels = EEGdata.columns[1:8]\n",
    "elif EEGdevice == 8:\n",
    "    channels = EEGdata.columns[0:8]\n",
    "\n",
    "# Format our data into an mne-friendly format\n",
    "ch_types = ['eeg']*len(channels)\n",
    "info = mne.create_info(ch_names=list(channels), sfreq=fs, ch_types=ch_types)\n",
    "rawData = EEGdata[channels].values\n",
    "rawData = np.transpose(rawData)\n",
    "raw = mne.io.array.RawArray(rawData, info)\n",
    "raw.set_montage(mne.channels.read_montage(kind='standard_1020'))\n",
    "raw.filter(l_freq=lf, h_freq=hf)\n",
    "\n",
    "# Make a copy of the original data just in case\n",
    "EEGdata[channels] = raw.get_data().T\n",
    "\n",
    "# Epoch the data\n",
    "epochs, epochs_norm = EpochBCIData(EEGdata, move_starts, rest_starts, rest_ends)\n",
    "\n",
    "# Organize trial types\n",
    "trial_type = OrganizeTrials(behavioralData, hasBaseline)\n",
    "\n",
    "# Get signal features\n",
    "alpha_power, beta_power = ExtractFeaturesBCI(epochs_norm, num_of_movements, ['C3','C4'], 1)\n",
    "motor_features = [alpha_power['C3'], alpha_power['C4'], beta_power['C3'], beta_power['C4']]\n",
    "motor_features = np.transpose(motor_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MI classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilew\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator SVC from version 0.20.2 when using version 0.20.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load latest model and its associated data\n",
    "models = glob.glob('../data/nile/' + subjID + '_MI_classifier_*')\n",
    "model_file = models[-1] # load the most recent model\n",
    "MI_model = pickle.load(open(model_file, 'rb'))\n",
    "\n",
    "models_data_list = glob.glob('../data/nile/' + subjID + '_data_for_MI_classifier_*')\n",
    "models_data = models_data_list[-1] # load the most recent model\n",
    "MI_data = np.load(models_data)\n",
    "X_loaded_MI = MI_data['X_not_scaled']\n",
    "y_loaded_MI = MI_data['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find ErrPs in current BCI data (this function loads the most recent ErrP model for this subject, epochs for error, creates features, and classifies).\n",
    "\n",
    "Make sure you've run Create_Error_Decoder first (right now it's just an .ipnyb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/nile\\nile_Error_classifier_2019-01-30-14-38-17.sav\n",
      "MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilew\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Users\\nilew\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    }
   ],
   "source": [
    "# Choose which examples to keep through confidence scoring\n",
    "X_new = motor_features\n",
    "y_new = trial_type\n",
    "\n",
    "CS, TL, preds_MI, preds_error, preds_error_proba, epochs, features, clf_error = ConfidenceScoreExamples(X_new, y_new, EEGdata, EEGdevice, fs, num_of_movements, move_starts, trial_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Update_MI_Decoder.ipnyb if you need more tinkering code to copy over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking CS\n",
    "Fixed it! Looks much better now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.58370814e-04, 3.60394644e-03, 1.09328275e-02, 1.51455076e-02,\n",
       "       9.96619814e-01, 9.99999609e-01, 3.12212408e-02, 8.09533611e-01,\n",
       "       2.90497339e-05, 9.99989654e-01, 1.00000000e+00, 9.99999969e-01,\n",
       "       7.66388264e-01, 9.96754280e-01, 1.20835842e-02, 1.00000000e+00,\n",
       "       7.77499315e-01, 1.00000000e+00, 9.99430544e-01, 9.99999972e-01,\n",
       "       1.00000000e+00, 1.00000000e+00, 8.95241740e-01, 1.73288761e-08,\n",
       "       1.00000000e+00, 9.99990377e-01, 1.00000000e+00, 9.99999967e-01,\n",
       "       9.99996998e-01, 1.00000000e+00, 1.07894692e-03, 9.48236088e-01,\n",
       "       9.78689734e-01, 1.84846271e-03, 1.29871795e-02, 4.70376612e-02,\n",
       "       9.89220428e-03, 3.61523034e-03, 2.02502900e-03, 9.99898926e-01,\n",
       "       8.06650013e-09, 9.92956100e-01, 2.70928865e-02, 1.93997454e-02,\n",
       "       1.12696963e-07, 4.29740132e-05, 6.91473426e-03, 9.89606241e-01,\n",
       "       9.99642885e-01, 1.00000000e+00, 1.00000000e+00, 6.48023368e-07,\n",
       "       9.92382914e-01, 1.14026510e-02, 2.97823493e-03, 9.99999734e-01,\n",
       "       9.99999999e-01, 9.93703112e-01, 1.50961386e-03, 9.41213671e-01,\n",
       "       9.99311346e-01, 6.46228931e-05, 9.95624001e-01, 3.88735585e-02,\n",
       "       9.36404610e-01, 9.99950909e-01, 1.00000000e+00, 9.34790916e-01,\n",
       "       9.23971869e-01, 1.07326950e-02, 9.99999999e-01, 5.77360982e-04,\n",
       "       9.99999513e-01, 4.54104338e-04, 9.99999997e-01, 9.99999996e-01,\n",
       "       9.99480870e-01, 1.00000000e+00, 9.99997190e-01, 1.23545618e-12,\n",
       "       1.00000000e+00, 9.99999942e-01, 1.00000000e+00, 9.99999975e-01,\n",
       "       3.86232817e-06, 9.99472913e-01, 9.99989286e-01, 9.99515870e-01,\n",
       "       1.00000000e+00, 1.00000000e+00, 8.39200931e-11, 1.00000000e+00,\n",
       "       9.99999989e-01, 6.22056101e-02, 9.99749232e-01])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(CS,'o')\n",
    "plt.xlabel('Examples')\n",
    "plt.ylabel('Confidence Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(CS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(TL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well do our confidence scores match with the true labels? (Note, this is just for error classification, not MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples: 95\n",
      "Percent of correctly scored examples: 55.78947368421052%\n",
      "----------------\n",
      "Confusion Matrix for Error Classification (not MI)\n",
      "[[41 22]\n",
      " [20 12]]\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# clf_error: our ErrP classifier\n",
    "# TL: true labels for the performance monitoring epochs in this BCI data\n",
    "# features: the features for the ErrP classifier for these performance monitoring epochs\n",
    "\n",
    "print('Total number of examples: ' + str(len(features)))\n",
    "print('Percent of correctly scored examples: ' + str(clf_error.score(features, TL)*100) + '%')\n",
    "print('----------------')\n",
    "print('Confusion Matrix for Error Classification (not MI)')\n",
    "print(confusion_matrix(TL, clf_error.predict(features)))\n",
    "print('----------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain / update\n",
    "Retrain and save MI classifier (with pre-scaled features), don't update error classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain\n",
    "adaptationType = 'CS' # either 'CS' for confidence score, or 'TL' for true label\n",
    "threshold = 0.7\n",
    "clf, X, X_not_scaled, y = RetrainDecoder(MI_model, CS, threshold, X_loaded_MI, y_loaded_MI, motor_features, trial_type, adaptationType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_loaded_MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(CS>0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1051"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save decoder and data it was trained/tested on\n",
    "SaveDecoderAndData(clf, X, X_not_scaled, y, subjID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
